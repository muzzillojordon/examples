{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\OneDrive\\Code\\Python\\Training\\ML\\Tests\\.venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "from pynvml import *\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  cuda\n",
      "fullDS: 891,  TrainDS:713,   ValidDS:178\n"
     ]
    }
   ],
   "source": [
    "#data Wokring functions:\n",
    "def imputPd(df, columnName, imputeObj):\n",
    "    df[columnName]= imputeObj.fit_transform(df[[columnName]]).ravel()\n",
    "    return df\n",
    "\n",
    "dev = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"CUDA Available: \", dev)\n",
    "\n",
    "\n",
    "#load Data********\n",
    "testData = pd.read_csv('titanic/test.csv')\n",
    "trainData = pd.read_csv('titanic/train.csv')\n",
    "trainData = trainData.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "testData = testData.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "# trainData.head()\n",
    "\n",
    "\n",
    "\n",
    "#Impute any Null Values if there are any null values\n",
    "trainDataNulls = trainData.columns[trainData.isna().any()].tolist()\n",
    "testDataNulls = testData.columns[testData.isna().any()].tolist()\n",
    "# print(testDataNulls,testDataNulls)\n",
    "imp = SimpleImputer(strategy=\"most_frequent\")\n",
    "\n",
    "if not len(trainDataNulls) == 0:\n",
    "    for colName in trainDataNulls:\n",
    "        trainData = imputPd(trainData, colName, imp)\n",
    "\n",
    "if not len(testDataNulls) == 0:\n",
    "    for colName in testDataNulls:\n",
    "        testData = imputPd(testData, colName, imp)\n",
    "\n",
    "\n",
    "#split out dependent and indepent vairables:\n",
    "x_train = trainData.drop('Survived', axis=1).copy()\n",
    "y_train =  trainData['Survived'].copy()\n",
    "x_test = testData.copy()\n",
    "# x_train.head()\n",
    "\n",
    "\n",
    "\n",
    "#convert text Labels to Numaric:\n",
    "leSexTrain = preprocessing.LabelEncoder()\n",
    "leSexTest = preprocessing.LabelEncoder()\n",
    "x_train['Sex'] = leSexTrain.fit_transform(x_train['Sex'])\n",
    "x_test['Sex'] = leSexTest.fit_transform(x_test['Sex'])\n",
    "\n",
    "leEmbarkedTrain = preprocessing.LabelEncoder()\n",
    "leEmbarkedTest = preprocessing.LabelEncoder()\n",
    "x_train['Embarked'] = leEmbarkedTrain.fit_transform(x_train['Embarked'])\n",
    "x_test['Embarked'] = leEmbarkedTest.fit_transform(x_test['Embarked'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#convert Data from Dataframe to tensor\n",
    "x_trainTen = torch.tensor(x_train.values, device=dev, dtype=torch.float64)\n",
    "# x_trainTen = x_trainTen.type(torch.LongTensor)\n",
    "# x_trainTen = x_trainTen.to(device)\n",
    "\n",
    "\n",
    "y_trainTen = torch.tensor(y_train.values, device=dev, dtype=torch.long)\n",
    "# y_trainTen = y_trainTen.type(torch.LongTensor)\n",
    "# y_trainTen = y_trainTen.to(device)\n",
    "\n",
    "x_testTen = torch.tensor(x_test.values, device=dev, dtype=torch.float64)\n",
    "# x_testTen = x_testTen.type(torch.LongTensor)\n",
    "# x_testTen = x_testTen.to(device)\n",
    "\n",
    "#load data into PyTorch dataset\n",
    "fullTrain_ds = TensorDataset(x_trainTen, y_trainTen)\n",
    "\n",
    "#Split trainging data into train and validate sets\n",
    "train_ds, valid_ds = torch.utils.data.random_split(fullTrain_ds, [.8, .2], generator=torch.Generator().manual_seed(42))\n",
    "print(f'fullDS: {len(fullTrain_ds)},  TrainDS:{len(train_ds)},   ValidDS:{len(valid_ds)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general Functions and classes for nn:\n",
    "class Mnist_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.linear1 = nn.Linear(12, 12)\n",
    "        self.linear1 = nn.Linear(7, 7, device=dev, dtype=torch.float64)\n",
    "        self.sigmoid1 = nn.Sigmoid()\n",
    "        self.linear2 = nn.Linear(7, 5, device=dev, dtype=torch.float64)\n",
    "        self.sigmoid2 = nn.Sigmoid()\n",
    "        self.linear3 = nn.Linear(5, 2, device=dev, dtype=torch.float64)\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "        # self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        lin1_out = self.linear1(xb)\n",
    "        sigmoid_out1 = self.sigmoid1(lin1_out)\n",
    "        sigmoid_out2 = self.sigmoid2(self.linear2(sigmoid_out1))\n",
    "        # lastLayer = self.softmax(self.linear3(sigmoid_out2))\n",
    "        # lastLayer = torch.flatten(lastLayer, 0)\n",
    "        return self.linear3(sigmoid_out2)\n",
    "\n",
    "\n",
    "\n",
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    pred = model(xb)\n",
    "    pred = torch.squeeze(pred, 0)\n",
    "    loss = loss_func(pred, yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)\n",
    "    \n",
    "\n",
    "\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        \n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        \n",
    "        if epoch%100 == 99:\n",
    "            print(epoch, val_loss, print_gpu_utilization())\n",
    "\n",
    "\n",
    "def get_data(train_ds, bs):\n",
    "    return DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 2019 MB.\n",
      "99 0.6265355549789884 None\n",
      "GPU memory occupied: 2012 MB.\n",
      "199 0.621718753027748 None\n",
      "GPU memory occupied: 2010 MB.\n",
      "299 0.6149312803255954 None\n",
      "GPU memory occupied: 2015 MB.\n",
      "399 0.616373578957956 None\n",
      "GPU memory occupied: 1973 MB.\n",
      "499 0.6264705212321665 None\n",
      "GPU memory occupied: 1968 MB.\n",
      "599 0.618307961059803 None\n",
      "GPU memory occupied: 1961 MB.\n",
      "699 0.6190673011365003 None\n",
      "GPU memory occupied: 1956 MB.\n",
      "799 0.618429914713917 None\n",
      "GPU memory occupied: 1950 MB.\n",
      "899 0.6181004967250859 None\n",
      "GPU memory occupied: 1950 MB.\n",
      "999 0.6154121546209899 None\n",
      "GPU memory occupied: 1955 MB.\n",
      "1099 0.611314392874266 None\n",
      "GPU memory occupied: 1958 MB.\n",
      "1199 0.6115306343744991 None\n",
      "GPU memory occupied: 1958 MB.\n",
      "1299 0.6077044019461962 None\n",
      "GPU memory occupied: 1958 MB.\n",
      "1399 0.5933972155231606 None\n",
      "GPU memory occupied: 1958 MB.\n",
      "1499 0.5890516604853812 None\n",
      "GPU memory occupied: 1954 MB.\n",
      "1599 0.583072642206988 None\n",
      "GPU memory occupied: 1946 MB.\n",
      "1699 0.5459298976208216 None\n",
      "GPU memory occupied: 1946 MB.\n",
      "1799 0.5141537461811465 None\n",
      "GPU memory occupied: 1946 MB.\n",
      "1899 0.5216393331953862 None\n",
      "GPU memory occupied: 1946 MB.\n",
      "1999 0.4681158096118146 None\n",
      "GPU memory occupied: 1946 MB.\n",
      "2099 0.4826119409515913 None\n",
      "GPU memory occupied: 1946 MB.\n",
      "2199 0.5146974278918252 None\n",
      "GPU memory occupied: 1946 MB.\n",
      "2299 0.44996040461899317 None\n",
      "GPU memory occupied: 1946 MB.\n",
      "2399 0.7664887996724981 None\n",
      "GPU memory occupied: 1946 MB.\n",
      "2499 0.4365766037524354 None\n",
      "GPU memory occupied: 1946 MB.\n",
      "2599 0.4182909411243685 None\n",
      "GPU memory occupied: 1946 MB.\n",
      "2699 0.5803387117276124 None\n",
      "GPU memory occupied: 1946 MB.\n",
      "2799 0.5248030695170572 None\n",
      "GPU memory occupied: 1946 MB.\n",
      "2899 0.5178178011625785 None\n",
      "GPU memory occupied: 1946 MB.\n",
      "2999 0.4324145165245894 None\n",
      "GPU memory occupied: 1946 MB.\n",
      "3099 0.5283837421516704 None\n",
      "GPU memory occupied: 1946 MB.\n",
      "3199 0.5620923863771438 None\n",
      "GPU memory occupied: 1946 MB.\n",
      "3299 0.4712930351913432 None\n",
      "GPU memory occupied: 1946 MB.\n",
      "3399 0.47441174189292445 None\n",
      "GPU memory occupied: 1946 MB.\n",
      "3499 0.4139376262077484 None\n",
      "GPU memory occupied: 1946 MB.\n",
      "3599 0.4282140758111703 None\n",
      "GPU memory occupied: 1946 MB.\n",
      "3699 0.4307928258724531 None\n",
      "GPU memory occupied: 1946 MB.\n",
      "3799 0.5015841827343326 None\n",
      "GPU memory occupied: 1946 MB.\n",
      "3899 0.4533948283350559 None\n",
      "GPU memory occupied: 1946 MB.\n",
      "3999 0.6672017806351486 None\n",
      "GPU memory occupied: 1946 MB.\n",
      "4099 0.4197405003338238 None\n",
      "GPU memory occupied: 1946 MB.\n",
      "4199 0.430760650890723 None\n",
      "GPU memory occupied: 1946 MB.\n",
      "4299 0.5953480948509395 None\n",
      "GPU memory occupied: 1962 MB.\n",
      "4399 0.4528567860174952 None\n",
      "GPU memory occupied: 1964 MB.\n",
      "4499 0.4319953884018141 None\n",
      "GPU memory occupied: 1951 MB.\n",
      "4599 0.43191511279676703 None\n",
      "GPU memory occupied: 1951 MB.\n",
      "4699 0.4251256578840966 None\n",
      "GPU memory occupied: 1951 MB.\n",
      "4799 0.4220931646110242 None\n",
      "GPU memory occupied: 1945 MB.\n",
      "4899 0.46664449645503336 None\n",
      "GPU memory occupied: 1945 MB.\n",
      "4999 0.5082490618690295 None\n",
      "GPU memory occupied: 1945 MB.\n",
      "5099 0.48910131134761475 None\n",
      "GPU memory occupied: 1945 MB.\n",
      "5199 0.4712999641842396 None\n",
      "GPU memory occupied: 1945 MB.\n",
      "5299 0.4179960049891766 None\n",
      "GPU memory occupied: 1976 MB.\n",
      "5399 0.426165612867749 None\n",
      "GPU memory occupied: 1987 MB.\n",
      "5499 0.44645709919120485 None\n",
      "GPU memory occupied: 1949 MB.\n",
      "5599 0.40936631704770965 None\n",
      "GPU memory occupied: 1738 MB.\n",
      "5699 0.4220642355352264 None\n",
      "GPU memory occupied: 1741 MB.\n",
      "5799 0.4395992715320138 None\n",
      "GPU memory occupied: 1738 MB.\n",
      "5899 0.4341392932057615 None\n",
      "GPU memory occupied: 1738 MB.\n",
      "5999 0.41763445366489693 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "6099 0.4170370357578185 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "6199 0.4799498077928319 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "6299 0.41554369986781986 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "6399 0.4618869476526405 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "6499 0.4989704934521409 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "6599 0.4367590345928164 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "6699 0.4398268320129704 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "6799 0.5043143040660473 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "6899 0.5424589960968765 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "6999 0.44753613576884627 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "7099 0.4353244257637781 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "7199 0.4244698894846854 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "7299 0.6032266303048095 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "7399 0.452454600735947 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "7499 0.650516634092546 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "7599 0.42968990482859737 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "7699 0.427693916602065 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "7799 0.439280018632355 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "7899 0.4201192173211645 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "7999 0.4347484469506942 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "8099 0.4541952466064057 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "8199 0.4181796142212746 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "8299 0.42341429092782734 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "8399 0.4337575354534719 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "8499 0.43499397680590074 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "8599 0.49604109927054374 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "8699 0.4353715859252437 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "8799 0.4250926602823448 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "8899 0.4990815350667841 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "8999 0.48306794698011984 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "9099 0.4297270536519913 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "9199 0.44900111472206417 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "9299 0.44418481382517594 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "9399 0.47509503158788896 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "9499 0.4406763680290859 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "9599 0.4273549299583435 None\n",
      "GPU memory occupied: 1734 MB.\n",
      "9699 0.49829969300827986 None\n",
      "GPU memory occupied: 1760 MB.\n",
      "9799 0.4251027711313086 None\n",
      "GPU memory occupied: 1791 MB.\n",
      "9899 0.4391630863624551 None\n",
      "GPU memory occupied: 1775 MB.\n",
      "9999 0.4656338623851521 None\n",
      "--- 331.61831879615784 seconds ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bs = 64\n",
    "# bs = 64\n",
    "epochs = 10000\n",
    "lr = .01\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs * 2)\n",
    "\n",
    "loss_func = F.cross_entropy\n",
    "# loss_func = F.mse_loss\n",
    "\n",
    "# model, opt = get_model()\n",
    "model = Mnist_Logistic()\n",
    "model.to(dev)\n",
    "opt = optim.SGD(model.parameters(), lr=lr)\n",
    "# opt = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "start_time = time.time()\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
    "\n",
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ff632cf3f7d45947118d20559029fb49804bdb8b041fe9c0a153afe74c122c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
