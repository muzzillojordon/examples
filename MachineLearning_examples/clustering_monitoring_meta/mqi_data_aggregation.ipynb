{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ***********Start Data aggregation\n",
    "# Data is is currently in the form of many samples of the same models at different periods of time\n",
    "# Aggregating in datal lake could of been done but with lack of user rights to data lake it is easier to do it here.\n",
    "#\n",
    "# *******************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***********START general data clean up and validation  is done in mqi_data_cleanup.ipynb*******************\n",
    "model_actions = pd.read_pickle(\"mqi_data_clean/model_actions_clean_cpy.pkl\")\n",
    "model_cases = pd.read_pickle(\"mqi_data_clean/model_cases_clean.pkl\")\n",
    "model_states = pd.read_pickle(\"mqi_data_clean/model_state_clean_cpy.pkl\")\n",
    "model_info = pd.read_pickle(\"mqi_data_clean/model_info_clean_cpy.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***********START MODEL INFO *******************\n",
    "\n",
    "\n",
    "def model_info_aggregate():\n",
    "    # MODEL AGE\n",
    "    modelinfo_age = pd.DataFrame()\n",
    "    modelinfo_age[\"age_inweeks\"] = model_info.groupby(\"modelid\", group_keys=False)[\n",
    "        [\"modelid\"]\n",
    "    ].count()\n",
    "\n",
    "    # GET MODEL CURRENT ACTIVE STATUS:\n",
    "    modelinfo_active = pd.DataFrame()\n",
    "    modelinfo_active[\n",
    "        [\n",
    "            \"currently_active\",\n",
    "            \"modeltype\",\n",
    "            \"position_code\",\n",
    "            \"position_description\",\n",
    "            \"site\",\n",
    "            \"position_class\",\n",
    "        ]\n",
    "    ] = model_info.groupby(\"modelid\", group_keys=False)[\n",
    "        [\n",
    "            \"current_active_value\",\n",
    "            \"modeltype\",\n",
    "            \"position_code\",\n",
    "            \"position_description\",\n",
    "            \"site\",\n",
    "            \"position_class\",\n",
    "        ]\n",
    "    ].first()\n",
    "\n",
    "    modelinfo_active = pd.get_dummies(modelinfo_active, columns=[\"currently_active\"])\n",
    "\n",
    "    # MODEL SAVE COUNT: calc frequency with model_state table age, see below for more detail\n",
    "    modelinfo_savecount = pd.DataFrame()\n",
    "    modelinfo_savecount[\"model_save_count\"] = model_info.groupby(\"modelid\")[\n",
    "        \"lastsavetime\"\n",
    "    ].nunique()\n",
    "\n",
    "    # MODEL RETRAIN COUNT: calc frequency with model_state table age, see below for more detail\n",
    "    modelinfo_rebuildcount = pd.DataFrame()\n",
    "    modelinfo_rebuildcount[\"model_build_count\"] = model_info.groupby(\"modelid\")[\n",
    "        \"lastbuildtime\"\n",
    "    ].nunique()\n",
    "\n",
    "    # MODEL SCORE\n",
    "    modelinfo_score = model_info.groupby(\"modelid\", group_keys=False)[\n",
    "        [\n",
    "            \"fixedlimitscore\",\n",
    "            \"gffscore\",\n",
    "            \"linregscore\",\n",
    "            \"logregscore\",\n",
    "            \"rollingaveragescore\",\n",
    "        ]\n",
    "    ].mean()\n",
    "    modelinfo_score[\"model_score_avg\"] = modelinfo_score.mean(axis=1)\n",
    "\n",
    "    # combine all aggregations\n",
    "    final_info = pd.concat(\n",
    "        [\n",
    "            modelinfo_age,\n",
    "            modelinfo_active,\n",
    "            modelinfo_savecount[[\"model_save_count\"]],\n",
    "            modelinfo_rebuildcount[[\"model_build_count\"]],\n",
    "            modelinfo_score[[\"model_score_avg\"]],\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # add alternative grouping for equipment type\n",
    "    final_info[\"pos_class_short\"] = final_info[\"position_class\"].str.split(\n",
    "        n=1, pat=\"-\", expand=True\n",
    "    )[0]\n",
    "    final_info[\"pos_class_short\"] = final_info[\"pos_class_short\"].str.strip()\n",
    "\n",
    "    unique_groups = (\n",
    "        final_info.groupby(\"pos_class_short\")[\"position_class\"].unique().apply(list)\n",
    "    )\n",
    "\n",
    "    unique_groups[\"MP-PUMP\"] = [\"MP-PUMP\"]\n",
    "    unique_groups[\"MP-COMP\"] = [\"MP-COMP\"]\n",
    "\n",
    "    remlst = [\"MP-PUMP\", \"MP-COMP\"]\n",
    "    [unique_groups[\"MP\"].remove(item) for item in remlst]\n",
    "    unique_groups.rename(index={\"MP\": \"MP-FAN_TURBN_GRBX_OTHER\"}, inplace=True)\n",
    "\n",
    "    unique_groups[\"FP-FIRED\"] = [\"FP-FIRED\"]\n",
    "    unique_groups[\"FP-EXCH\"] = [\"FP-EXCH\"]\n",
    "    unique_groups[\"FP-tank-vessel\"] = [\"FP-TANK\", \"FP-VESSL\"]\n",
    "\n",
    "    remlst = [\"FP-FIRED\", \"FP-EXCH\", \"FP-TANK\", \"FP-VESSL\"]\n",
    "    [unique_groups[\"FP\"].remove(item) for item in remlst]\n",
    "    unique_groups.rename(index={\"FP\": \"FP-COMP_VALVE_PIPE_OTHER\"}, inplace=True)\n",
    "\n",
    "    unique_groups[\"IP-VALVE\"] = [\"IP-VALVE\"]\n",
    "    unique_groups[\"IP\"].remove(\"IP-VALVE\")\n",
    "    unique_groups.rename(index={\"IP\": \"IP-LOOPS_XMTR_OTHER\"}, inplace=True)\n",
    "\n",
    "    unique_groups[\"OP\"] = unique_groups[\"OP\"] + unique_groups[\"P\"]\n",
    "    unique_groups.drop(\"P\", inplace=True)\n",
    "    unique_groups.rename(index={\"OP\": \"OP_P\"}, inplace=True)\n",
    "\n",
    "    for newcls, clslst in zip(unique_groups.index, unique_groups):\n",
    "        final_info.loc[\n",
    "            final_info[\"position_class\"].isin(clslst), \"position_class_group\"\n",
    "        ] = newcls\n",
    "\n",
    "    # drop unused columns\n",
    "    final_info.drop(\n",
    "        columns=[\n",
    "            \"position_class\",\n",
    "            \"pos_class_short\",\n",
    "            \"position_description\",\n",
    "            \"position_code\",\n",
    "        ],\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    final_info.loc[final_info['position_class_group'].isna(), 'position_class_group'] = 'unknown'\n",
    "    final_info.loc[final_info['site'].isna(), 'site'] = 'unknown'\n",
    "    return final_info\n",
    "\n",
    "\n",
    "final_info = model_info_aggregate()\n",
    "# ***********END MODEL INFO*******************\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***********START MODEL ACTIONS *******************\n",
    "def model_actions_aggregate():\n",
    "    # get averages of model values for 'actual', 'expected', 'upper', and 'lower':\n",
    "    # this is not used in final table instead using  model_state table, not adding because there are not values for every model ID like model state\n",
    "    model_values = model_actions[\n",
    "        [\"modelid\", \"actual\", \"expected\", \"upper\", \"lower\"]\n",
    "    ].copy()\n",
    "    model_values = model_values.groupby(\"modelid\")[\n",
    "        [\"actual\", \"expected\", \"upper\", \"lower\"]\n",
    "    ].mean()\n",
    "\n",
    "    # TOUCH COUNT: add number of touches, ie. how many total times any action was performed to a model. NOTE Every row is an action performed\n",
    "    model_touches = model_actions.copy()\n",
    "    model_touches = model_actions.groupby(\"modelid\", group_keys=False)[\n",
    "        [\"modelid\"]\n",
    "    ].count()\n",
    "    model_touches = model_touches.rename(columns={\"modelid\": \"touches_count\"})\n",
    "\n",
    "    # LENGTH OF NOTE: get average length of notes for each action on each model ID\n",
    "    mod_comnt_temp = model_actions[[\"modelid\", \"actionnote\"]].copy()\n",
    "    mod_comnt_temp[\"actionnoteLen\"] = model_actions[\"actionnote\"].apply(len)\n",
    "    model_comments_len = mod_comnt_temp.groupby(\"modelid\", group_keys=False)[\n",
    "        [\"actionnoteLen\"]\n",
    "    ].mean()\n",
    "\n",
    "    model_comments_len.rename(\n",
    "        columns={\"actionnoteLen\": \"action_note_len_avg\"}, inplace=True\n",
    "    )\n",
    "\n",
    "    # ACTION TYPE COUNT: get count of each type of actiontype for each Model ID.\n",
    "    actionTypes_df = model_actions[[\"modelid\", \"actiontype\"]].copy()\n",
    "    actionTypes_df = actionTypes_df.set_index(\"modelid\")\n",
    "    # create columns for all values\n",
    "    actionTypes_df = pd.get_dummies(actionTypes_df, columns=[\"actiontype\"])\n",
    "    actionTypes_df = actionTypes_df.groupby(\"modelid\", group_keys=False).sum()\n",
    "\n",
    "    #combine dataframes\n",
    "    return pd.concat(\n",
    "        [model_values, model_comments_len, actionTypes_df, model_touches], axis=1\n",
    "    )\n",
    "\n",
    "\n",
    "final_actions_df = model_actions_aggregate()\n",
    "\n",
    "# ***********END MODEL ACTIONS*******************\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jordom2\\AppData\\Local\\Temp\\ipykernel_6872\\3235251916.py:18: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  alertTypes_df = alertTypes_df.groupby(\"modelid\", group_keys=False).sum()\n"
     ]
    }
   ],
   "source": [
    "# ***********START MODEL STATES *******************\n",
    "def model_state_aggregate():\n",
    "    # AGG ALERT TYPES: alerts are doubled up, ie on cell may have 'AAS,HHA' and another may have 'HHA' so this creates many columns\n",
    "    alertTypes_df = model_states[[\"modelid\", \"activealerts\"]].copy()\n",
    "    alertTypes_df = alertTypes_df.set_index(\"modelid\")\n",
    "\n",
    "    unique_alerts = alertTypes_df[\"activealerts\"].unique()\n",
    "    unique_alerts_lst = list(\n",
    "        set([alert for alerts in unique_alerts for alert in alerts.split(\",\")])\n",
    "    )\n",
    "    alertTypes_df[unique_alerts_lst] = 0\n",
    "    for i in range(len(unique_alerts_lst)):\n",
    "        alertTypes_df.loc[\n",
    "            alertTypes_df[\"activealerts\"].str.contains(unique_alerts_lst[i]),\n",
    "            unique_alerts_lst[i],\n",
    "        ] = 1\n",
    "    # sum up all each alert type for each model ID\n",
    "    alertTypes_df = alertTypes_df.groupby(\"modelid\", group_keys=False).sum()\n",
    "\n",
    "    #Calculate model age. Each row is a week (samples taken at 1 week interval)\n",
    "    alertTypes_df[\"model_age\"] = (\n",
    "        model_states.groupby(\"modelid\", group_keys=False)[\"modelid\"].count().copy()\n",
    "    )\n",
    "\n",
    "    alertTypes_df['in_alert'] = alertTypes_df[['AAF', 'LLA', 'OSC', 'WOR', 'AAS', 'HHA', 'FRQ']].sum(axis=1)\n",
    "    #NOTE: \"no alerts\" was set for all null values in \"active alerts column\" in mqi_data_clean\n",
    "\n",
    "\n",
    "    #!when looking at data noticed that actual_vs_expected_percdiff, upper_vs_expected_percdiff and lower_vs_expected_percdiff had alot of values == 200\n",
    "    #this is when actual and expected are 0 (or very near 0), possible remove these values before doing calc, for leave in and see if maybe it is a quality signifier in cluster\n",
    "    #! fixed limits will have same value for actual and expected\n",
    "    # AGG AVG VALUES: convert values to percent difference more important is how model is predicting relative to self(ie. actual vs expected)\n",
    "    values_lst = [\"actual\", \"expected\", \"upper\", \"lower\"]\n",
    "    state_values = model_states.groupby(\"modelid\")[values_lst].mean().copy()\n",
    "    state_values_orig = state_values.copy()\n",
    "\n",
    "    state_values[\"actual_vs_expected_percdiff\"] = (\n",
    "        ((state_values[\"actual\"] - state_values[\"expected\"]).abs())\n",
    "        / (((state_values[\"actual\"] + state_values[\"expected\"]).abs())/ 2)\n",
    "    ) * 100\n",
    "\n",
    "    state_values[\"upper_vs_actual_percdiff\"] = (\n",
    "        ((state_values[\"upper\"] - state_values[\"actual\"]).abs())\n",
    "        / (((state_values[\"upper\"] + state_values[\"actual\"]).abs()) / 2)\n",
    "    ) * 100\n",
    "    state_values[\"lower_vs_actual_percdiff\"] = (\n",
    "        ((state_values[\"lower\"] - state_values[\"actual\"]).abs())\n",
    "        / (((state_values[\"lower\"] + state_values[\"actual\"]).abs()) / 2)\n",
    "    ) * 100\n",
    "\n",
    "    # remove old columns and fill null values with 0 (if avg values are 0 percdiff will make it null, all rows before grouping had NO NULL values)\n",
    "    state_values.drop([\"actual\", \"expected\", \"upper\", \"lower\"], axis=1, inplace=True)\n",
    "    # state_values.fillna(0, inplace=True)\n",
    "\n",
    "    return pd.concat([alertTypes_df, state_values], axis=1)\n",
    "\n",
    "\n",
    "final_state_df = model_state_aggregate()\n",
    "# ***********END MODEL STATES *******************\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 14884.0 cases of a total 2786 cases\n"
     ]
    }
   ],
   "source": [
    "# ***********START CASES STATES *******************\n",
    "def model_cases_aggregate(model_cases, model_casecount):\n",
    "\n",
    "    # group by case ID to get count of each equipment case\n",
    "    model_casesgroup = model_cases.groupby(\"casemgmt_equipment_id\", group_keys=False)[\n",
    "        [\"casemgmt_equipment_id\"]\n",
    "    ].count()\n",
    "\n",
    "    # map equipment ID back to final_info DF to get case count\n",
    "    model_casecount[\"case_count\"] = model_casecount[\"position_code\"].map(\n",
    "        model_casesgroup[\"casemgmt_equipment_id\"]\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Found: {model_casecount['case_count'].sum()} cases of a total {model_casesgroup['casemgmt_equipment_id'].sum()} cases\"\n",
    "    )\n",
    "\n",
    "    model_casecount.drop(columns='position_code', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    return model_casecount\n",
    "\n",
    "\n",
    "#!SHOULD BE ABLE TO REPLACE WITH FINAL INFO\n",
    "# add these columns after model_info is aggregated, use to link cases and equipment type\n",
    "model_info_addedcols = pd.read_pickle(\n",
    "    \"mqi_data_clean/model_info_clean_added_col_3.pkl\"\n",
    ")\n",
    "final_case_df = model_cases_aggregate(model_cases, model_info_addedcols[['position_code']].copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22101, 39)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ***********Start ASSEMBLE Aggregated DF *******************\n",
    "def merge_all_tables():\n",
    "    # combine model_info and model_state aggregated tables\n",
    "    aggreg_df = pd.merge(\n",
    "        final_info, final_state_df, left_index=True, right_index=True, how=\"left\"\n",
    "    )\n",
    "\n",
    "    aggreg_df = pd.merge(\n",
    "        aggreg_df, final_case_df, left_index=True, right_index=True, how=\"left\"\n",
    "    )\n",
    "\n",
    "    # get names for columns from actions table to add to aggregated_df, combine model_actions to aggregated table\n",
    "    actions_df_col = list(final_actions_df.columns)\n",
    "    actions_df_col = actions_df_col[4 : len(actions_df_col)]\n",
    "    aggreg_df = pd.merge(\n",
    "        aggreg_df,\n",
    "        final_actions_df[actions_df_col],\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    return aggreg_df\n",
    "\n",
    "\n",
    "aggreg_df = merge_all_tables()\n",
    "aggreg_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average amount age off:0.00936609203203475\n",
      "max amount age off:4\n",
      "number of values off: combined\n",
      "True        18782\n",
      "False        3319\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Difference looks due to model_info table missing random rows compared to model_state. \n",
    "Difference is small, worst case is 3% different (only 3 cases near this percent).\n",
    "    ACTION: use model_state \"model_age\", this value will better align with more aggregated rows (ie. 'actual, expected, etc.)\n",
    "\"\"\"\n",
    "def check_mod_age():\n",
    "    model_age_check = aggreg_df[[\"age_inweeks\", \"model_age\"]].copy()\n",
    "    model_age_check[\"combined\"] = aggreg_df[\"age_inweeks\"] == aggreg_df[\"model_age\"]\n",
    "    model_age_check[\"how_off\"] = aggreg_df[\"age_inweeks\"] - aggreg_df[\"model_age\"]\n",
    "\n",
    "    print(f\"average amount age off:{model_age_check['how_off'].mean()}\")\n",
    "    print(f\"max amount age off:{model_age_check['how_off'].max()}\")\n",
    "    print(f\"number of values off: {model_age_check[['combined']].value_counts()}\")\n",
    "\n",
    "check_mod_age()\n",
    "\n",
    "aggreg_df.drop(columns=[\"age_inweeks\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['modeltype', 'site', 'currently_active_False', 'currently_active_True',\n",
       "       'model_save_count', 'model_build_count', 'model_score_avg',\n",
       "       'position_class_group', 'LLA', 'AAS', 'AAF', 'noAlert', 'WOR', 'FRQ',\n",
       "       'HHA', 'OSC', 'model_age', 'in_alert', 'actual_vs_expected_percdiff',\n",
       "       'upper_vs_actual_percdiff', 'lower_vs_actual_percdiff', 'case_count',\n",
       "       'action_note_len_avg', 'actiontype_Clear Alert Status',\n",
       "       'actiontype_Diagnose Cleared', 'actiontype_Diagnose Set',\n",
       "       'actiontype_Ignore Expiration', 'actiontype_Ignore Set',\n",
       "       'actiontype_Model Maintenance Cleared',\n",
       "       'actiontype_Model Maintenance Set', 'actiontype_Note Added',\n",
       "       'actiontype_Quick Watch Set', 'actiontype_Stop Ignoring',\n",
       "       'actiontype_Watch Cleared', 'actiontype_Watch Expiration',\n",
       "       'actiontype_Watch Override', 'actiontype_Watch Set', 'touches_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggreg_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to frequency: Models created in past could collect alerts so use freq, each row ingested 1 time a week, count of model ID == model age\n",
    "def model_alerts_to_freq():\n",
    "    col_lst = [\n",
    "        'WOR', 'HHA', 'OSC', 'FRQ', 'noAlert', 'LLA',\n",
    "       'AAS', 'AAF', 'in_alert'\n",
    "        ]\n",
    "    col_lst_new = [(str(col) + \"_freq\") for col in col_lst]\n",
    "\n",
    "    # convert To action counts to Frequency using model_age from model_state aggregations\n",
    "    aggreg_df[col_lst] = aggreg_df[col_lst].div(aggreg_df[\"model_age\"].values, axis=0)\n",
    "    aggreg_df.rename(columns=dict(zip(col_lst, col_lst_new)), inplace=True)\n",
    "\n",
    "    # if actions is 0 .div ends up in with null value, replace with 0\n",
    "    aggreg_df[col_lst_new] = aggreg_df[col_lst_new].fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "def model_actions_to_freq():\n",
    "    col_lst = [\n",
    "        'actiontype_Clear Alert Status',\n",
    "        'actiontype_Diagnose Cleared',\n",
    "        'actiontype_Diagnose Set',\n",
    "        'actiontype_Ignore Expiration',\n",
    "        'actiontype_Ignore Set',\n",
    "        'actiontype_Model Maintenance Cleared',\n",
    "        'actiontype_Model Maintenance Set',\n",
    "        'actiontype_Note Added',\n",
    "        'actiontype_Quick Watch Set',\n",
    "        'actiontype_Stop Ignoring',\n",
    "        'actiontype_Watch Cleared',\n",
    "        'actiontype_Watch Expiration',\n",
    "        'actiontype_Watch Override',\n",
    "        'actiontype_Watch Set',\n",
    "        'touches_count'\n",
    "        ]\n",
    "    # col_lst = list(final_actions_df.columns)\n",
    "    # col_lst = col_lst[5 : len(col_lst)]\n",
    "    col_lst_new = [(str(col) + \"_freq\") for col in col_lst]\n",
    "\n",
    "    # convert To action counts to Frequency using model_age from model_state aggregations\n",
    "    aggreg_df[col_lst] = aggreg_df[col_lst].div(aggreg_df[\"model_age\"].values, axis=0)\n",
    "    aggreg_df.rename(columns=dict(zip(col_lst, col_lst_new)), inplace=True)\n",
    "\n",
    "    # if actions is 0 .div ends up in with null value, replace with 0\n",
    "    aggreg_df[col_lst_new] = aggreg_df[col_lst_new].fillna(0)\n",
    "\n",
    "\n",
    "def model_info_to_freq():\n",
    "    col_lst = [\"model_save_count\", \"model_build_count\"]\n",
    "    col_lst_new = [\"model_save_freq\", \"model_build_freq\"]\n",
    "    aggreg_df[col_lst] = aggreg_df[col_lst].div(aggreg_df[\"model_age\"].values, axis=0)\n",
    "    aggreg_df.rename(columns=dict(zip(col_lst, col_lst_new)), inplace=True)\n",
    "\n",
    "def model_cases_to_freq():\n",
    "    col_lst = [\"case_count\"]\n",
    "    col_lst_new = [\"case_count_freq\"]\n",
    "\n",
    "    #add new column to keep case count for final metrics \n",
    "    aggreg_df[col_lst_new] = aggreg_df[col_lst].div(aggreg_df[\"model_age\"].values, axis=0)\n",
    "    # aggreg_df.rename(columns=dict(zip(col_lst, col_lst_new)), inplace=True)\n",
    "    # fill any null values for cases\n",
    "    aggreg_df[[\"case_count_freq\"]] = aggreg_df[[\"case_count_freq\"]].fillna(0)\n",
    "\n",
    "\n",
    "model_alerts_to_freq()\n",
    "model_actions_to_freq()\n",
    "model_info_to_freq()\n",
    "model_cases_to_freq()\n",
    "\n",
    "#some models had no action note comments, so after merge value was null\n",
    "aggreg_df['action_note_len_avg'] = aggreg_df['action_note_len_avg'].fillna(0)\n",
    "aggreg_df['case_count'] = aggreg_df['case_count'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['modeltype', 'site', 'currently_active_False', 'currently_active_True',\n",
       "       'model_save_freq', 'model_build_freq', 'model_score_avg',\n",
       "       'position_class_group', 'LLA_freq', 'AAS_freq', 'AAF_freq',\n",
       "       'noAlert_freq', 'WOR_freq', 'FRQ_freq', 'HHA_freq', 'OSC_freq',\n",
       "       'model_age', 'in_alert_freq', 'actual_vs_expected_percdiff',\n",
       "       'upper_vs_actual_percdiff', 'lower_vs_actual_percdiff', 'case_count',\n",
       "       'action_note_len_avg', 'actiontype_Clear Alert Status_freq',\n",
       "       'actiontype_Diagnose Cleared_freq', 'actiontype_Diagnose Set_freq',\n",
       "       'actiontype_Ignore Expiration_freq', 'actiontype_Ignore Set_freq',\n",
       "       'actiontype_Model Maintenance Cleared_freq',\n",
       "       'actiontype_Model Maintenance Set_freq', 'actiontype_Note Added_freq',\n",
       "       'actiontype_Quick Watch Set_freq', 'actiontype_Stop Ignoring_freq',\n",
       "       'actiontype_Watch Cleared_freq', 'actiontype_Watch Expiration_freq',\n",
       "       'actiontype_Watch Override_freq', 'actiontype_Watch Set_freq',\n",
       "       'touches_count_freq', 'case_count_freq'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggreg_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_info.to_pickle(\"mqi_data_aggregated/final_info_df.pkl\")\n",
    "final_state_df.to_pickle(\"mqi_data_aggregated/final_state_df.pkl\")\n",
    "final_actions_df.to_pickle(\"mqi_data_aggregated/final_actions_df.pkl\")\n",
    "aggreg_df.to_pickle(\"mqi_data_aggregated/aggreg_df.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bfddfb6c7bd0c938935be39c4b0e4a8fb77352881edfeed0e8c2bea19a1c4275"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
