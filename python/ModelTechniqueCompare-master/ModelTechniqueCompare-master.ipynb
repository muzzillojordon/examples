{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d3c1bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant, open source \"library modules/packages\"\n",
    "import sys\n",
    "import time\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "import pdb\n",
    "import asyncio\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import (\n",
    "    GridspecLayout,\n",
    "    Layout,\n",
    "    Button,\n",
    "    HBox,\n",
    "    VBox,\n",
    "    jslink,\n",
    "    Box,\n",
    "    TwoByTwoLayout,\n",
    "    AppLayout,\n",
    ")\n",
    "from IPython.display import HTML, Javascript, display, clear_output\n",
    "from IPython import display as dis\n",
    "import ipydatetime\n",
    "from IPython.core.debugger import set_trace\n",
    "import qgrid\n",
    "from datetime import datetime\n",
    "from seeq import spy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "import pytz\n",
    "from importlib import reload\n",
    "\n",
    "spy.options.friendly_exceptions = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63528601",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f097e9e32734f22953b44bd6701e3b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AppLayout(children=(TwoByTwoLayout(children=(HBox(children=(Valid(value=False, description='Valid!', layout=Laâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# **************User Input FORM Display Code: Start**************\n",
    "genLayout_1 = Layout(width=\"auto\", height=\"auto\")\n",
    "genStyle_1 = {\"description_width\": \"initial\"}\n",
    "\n",
    "investigationDateStartSelect = widgets.DatePicker(\n",
    "    description=\"Investigation Start Date\",\n",
    "    value=(date.today() - timedelta(days=15)),\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    disabled=False,\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "\n",
    "investigationDateEndSelect = widgets.DatePicker(\n",
    "    description=\"Investigation End Date\",\n",
    "    value=date.today(),\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    disabled=False,\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "site_DD = widgets.Dropdown(\n",
    "    options=[\n",
    "        (\"FasdfC\", \"Fasf\"),\n",
    "        (\"FfdHeetB\", \"dseeB\"),\n",
    "        (\"df\", \"asdf\"),\n",
    "        (\"FssM\", \"FeeeM\"),\n",
    "        (\"asdf\", \"FBadsf\"),\n",
    "    ],\n",
    "    description=\"Site\",\n",
    "    disabled=False,\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\", align_items=\"stretch\"),\n",
    ")\n",
    "\n",
    "# 40PI6085\n",
    "piTag_tb = widgets.Text(\n",
    "    value=\"\",\n",
    "    description=\"Pasdf:\",\n",
    "    disabled=False,\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "# E0310P106A.Run_Status\n",
    "RunStatusTag_tb = widgets.Text(\n",
    "    value=\"\",\n",
    "    description=\"RunStatus PiTag:\",\n",
    "    disabled=False,\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "RunStatusValue_tb = widgets.Text(\n",
    "    value=\"\",\n",
    "    disabled=False,\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "RunStatusOperator_DD = widgets.Dropdown(\n",
    "    options=[(\">\", \">\"), (\"==\", \"==\"), (\"~=\", \"~=\"), (\"<\", \"<\")],\n",
    "    disabled=False,\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\", align_items=\"stretch\"),\n",
    ")\n",
    "\n",
    "TestToRun_STB = widgets.SelectMultiple(\n",
    "    options=[\n",
    "        \"aasfuntLo, Deaasdgbange)\",\n",
    "        \"asfbhpLag asfbhpLag)\",\n",
    "        \"Foreca st asfbhpLag- Zadfdsd-Score: (Z-Score + dsfdf, asfbhpLag)\",\n",
    "        \"sadfr: -V + StartDate, EndDate, asfbhpLag)\",\n",
    "        \n",
    "    ],\n",
    "    description=\"Tests to Run:\",\n",
    "    description_tooltip=\"Multiple values can be selected with shift and/or ctrl\",\n",
    "    value=[\n",
    "        \"Z-Score: (WindowSize, WindowFreq, StdDevCountHi, StdDevCountLo, Deadband, StartUpLag, MinChange)\"\n",
    "    ],\n",
    "    disabled=False,\n",
    "    style=genStyle_1,\n",
    "    layout=Layout(width=\"auto\", height=\"100%\"),\n",
    ")\n",
    "\n",
    "manualLoadButt = widgets.Button(\n",
    "    description=\"Load\",\n",
    "    disabled=False,\n",
    "    button_style=\"info\",\n",
    "    tooltip=\"Click me\",\n",
    "    icon=\"check\",\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "manualClearButt = widgets.Button(\n",
    "    description=\"Clear\",\n",
    "    disabled=True,\n",
    "    button_style=\"warning\",\n",
    "    tooltip=\"Click me\",\n",
    "    icon=\"check\",\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "manualTestButt = widgets.Button(\n",
    "    description=\"Run Test\",\n",
    "    disabled=True,\n",
    "    button_style=\"success\",\n",
    "    tooltip=\"Click me\",\n",
    "    icon=\"check\",\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "\n",
    "WindowSizeSldr = widgets.IntRangeSlider(\n",
    "    value=[30, 35],\n",
    "    min=1,\n",
    "    max=180,\n",
    "    step=1,\n",
    "    description=\"Wind9898e(df):\",\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation=\"horizontal\",\n",
    "    readout=True,\n",
    "    readout_format=\"d\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "WindowFreqSldr = widgets.IntRangeSlider(\n",
    "    value=[3, 4],\n",
    "    min=1,\n",
    "    max=15,\n",
    "    step=1,\n",
    "    description=\"Wieeendosdeay):\",\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation=\"horizontal\",\n",
    "    readout=True,\n",
    "    readout_format=\"d\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "StdDevCountHiSldr = widgets.IntRangeSlider(\n",
    "    value=[2, 3],\n",
    "    min=1,\n",
    "    max=8,\n",
    "    step=1,\n",
    "    description=\"asdf:\",\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation=\"horizontal\",\n",
    "    readout=True,\n",
    "    readout_format=\"d\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "StdDevCountLoSldr = widgets.IntRangeSlider(\n",
    "    value=[2, 3],\n",
    "    min=1,\n",
    "    max=8,\n",
    "    step=1,\n",
    "    description=\"sdfg:\",\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation=\"horizontal\",\n",
    "    readout=True,\n",
    "    readout_format=\"d\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "DeadbandSldr = widgets.IntRangeSlider(\n",
    "    value=[21, 31],\n",
    "    min=1,\n",
    "    max=180,\n",
    "    step=10,\n",
    "    description=\"sdfg (mdshin):\",\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation=\"horizontal\",\n",
    "    readout=True,\n",
    "    readout_format=\"d\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "StartUpLagSldr = widgets.IntRangeSlider(\n",
    "    value=[0, 0],\n",
    "    min=0,\n",
    "    max=24,\n",
    "    step=1,\n",
    "    description=\"dsfg (hr):\",\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation=\"horizontal\",\n",
    "    readout=True,\n",
    "    readout_format=\"d\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "MinChangeSldr = widgets.IntRangeSlider(\n",
    "    value=[0, 0],\n",
    "    min=0,\n",
    "    max=24,\n",
    "    step=1,\n",
    "    description=\"fghj:\",\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation=\"horizontal\",\n",
    "    readout=True,\n",
    "    readout_format=\"d\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "FixedLimHISldr = widgets.IntRangeSlider(\n",
    "    value=[0, 1],\n",
    "    min=-9999,\n",
    "    max=9999,\n",
    "    step=1,\n",
    "    description=\"fghj fghj hh:\",\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation=\"horizontal\",\n",
    "    readout=True,\n",
    "    readout_format=\"d\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "FixedLimLOSldr = widgets.IntRangeSlider(\n",
    "    value=[0, 1],\n",
    "    min=-9999,\n",
    "    max=9999,\n",
    "    step=1,\n",
    "    description=\"Fiyyxehw:\",\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation=\"horizontal\",\n",
    "    readout=True,\n",
    "    readout_format=\"d\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "outOfBoundsHiSldr = widgets.IntRangeSlider(\n",
    "    value=[0, 1],\n",
    "    min=-9999,\n",
    "    max=9999,\n",
    "    step=1,\n",
    "    description=\"Ouui:\",\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation=\"horizontal\",\n",
    "    readout=True,\n",
    "    readout_format=\"d\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "outOfBoundsLoSldr = widgets.IntRangeSlider(\n",
    "    value=[0, 1],\n",
    "    min=-9999,\n",
    "    max=9999,\n",
    "    step=1,\n",
    "    description=\"Ou4ow:\",\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation=\"horizontal\",\n",
    "    readout=True,\n",
    "    readout_format=\"d\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "DurationSldr = widgets.IntRangeSlider(\n",
    "    value=[29, 30],\n",
    "    min=1,\n",
    "    max=365,\n",
    "    step=1,\n",
    "    description=\"Tra46h:\",\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation=\"horizontal\",\n",
    "    readout=True,\n",
    "    readout_format=\"d\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "ForecastDurationSldr = widgets.IntRangeSlider(\n",
    "    value=[13, 14],\n",
    "    min=1,\n",
    "    max=30,\n",
    "    step=1,\n",
    "    description=\"Feeeorecfgion(d):\",\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation=\"horizontal\",\n",
    "    readout=True,\n",
    "    readout_format=\"d\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "\n",
    "DaysToLimTargetSldr = widgets.IntSlider(\n",
    "    description=\"Datget:\",\n",
    "    min=-9999,\n",
    "    max=9999,\n",
    "    step=1,\n",
    "    value=0,\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "DaysToLimTypeDD = widgets.Dropdown(\n",
    "    options=[(\"High\", \"High\"), (\"Low\", \"Low\")],\n",
    "    description=\"Dayhjmpe\",\n",
    "    disabled=False,\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "DaysToLimSigTB = widgets.Text(\n",
    "    value=\"\",\n",
    "    description=\"Dayiuyygnal:\",\n",
    "    disabled=False,\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "\n",
    "forcastLimWindowStart = widgets.DatePicker(\n",
    "    description=\"Forcayiate\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    disabled=False,\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "forcastLimWindowEnd = widgets.DatePicker(\n",
    "    description=\"Forcasuykate\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    disabled=False,\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "\n",
    "ModelSettingLabel = widgets.Label(\n",
    "    value=\"Model Settings:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "StepsLabel = widgets.Label(\n",
    "    value=\"STEPS:\",\n",
    "    sstyle={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "WindowSizeStepSldr = widgets.IntSlider(\n",
    "    value=5,\n",
    "    min=1,\n",
    "    max=30,\n",
    "    step=1,\n",
    "    description=\"\",\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation=\"horizontal\",\n",
    "    readout=True,\n",
    "    readout_format=\"d\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "WindowFreqStepSldr = widgets.IntSlider(\n",
    "    value=5,\n",
    "    min=1,\n",
    "    max=30,\n",
    "    step=1,\n",
    "    description=\"\",\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation=\"horizontal\",\n",
    "    readout=True,\n",
    "    readout_format=\"d\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "StdDevCountHiStepSldr = widgets.IntSlider(\n",
    "    value=1,\n",
    "    min=1,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    description=\"\",\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation=\"horizontal\",\n",
    "    readout=True,\n",
    "    readout_format=\"d\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "DeadbandStepSldr = widgets.IntSlider(\n",
    "    value=10,\n",
    "    min=10,\n",
    "    max=30,\n",
    "    step=10,\n",
    "    description=\"\",\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation=\"horizontal\",\n",
    "    readout=True,\n",
    "    readout_format=\"d\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "StartUpLagStepSldr = widgets.IntSlider(\n",
    "    value=1,\n",
    "    min=1,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    description=\"\",\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation=\"horizontal\",\n",
    "    readout=True,\n",
    "    readout_format=\"d\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "MinChangeStepSldr = widgets.IntSlider(\n",
    "    value=1,\n",
    "    min=1,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    description=\"\",\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation=\"horizontal\",\n",
    "    readout=True,\n",
    "    readout_format=\"d\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "\n",
    "FixedLimHIStepSldr = widgets.IntSlider(\n",
    "    value=1,\n",
    "    min=1,\n",
    "    max=9999,\n",
    "    step=1,\n",
    "    description=\"\",\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation=\"horizontal\",\n",
    "    readout=True,\n",
    "    readout_format=\"d\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "FixedLimLOStepSldr = widgets.IntSlider(\n",
    "    value=1,\n",
    "    min=1,\n",
    "    max=9999,\n",
    "    step=1,\n",
    "    description=\"\",\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation=\"horizontal\",\n",
    "    readout=True,\n",
    "    readout_format=\"d\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "outOfBoundsHiStepSldr = widgets.IntSlider(\n",
    "    value=1,\n",
    "    min=1,\n",
    "    max=9999,\n",
    "    step=1,\n",
    "    description=\"\",\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation=\"horizontal\",\n",
    "    readout=True,\n",
    "    readout_format=\"d\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "outOfBoundsLoStepSldr = widgets.IntSlider(\n",
    "    value=1,\n",
    "    min=1,\n",
    "    max=9999,\n",
    "    step=1,\n",
    "    description=\"\",\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation=\"horizontal\",\n",
    "    readout=True,\n",
    "    readout_format=\"d\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "DurationStepSldr = widgets.IntSlider(\n",
    "    value=1,\n",
    "    min=1,\n",
    "    max=30,\n",
    "    step=1,\n",
    "    description=\"\",\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation=\"horizontal\",\n",
    "    readout=True,\n",
    "    readout_format=\"d\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "\n",
    "ForecastDurationStepSldr = widgets.IntSlider(\n",
    "    value=1,\n",
    "    min=1,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    description=\"\",\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation=\"horizontal\",\n",
    "    readout=True,\n",
    "    readout_format=\"d\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "\n",
    "AddAnomalyButt = widgets.Button(\n",
    "    description=\"Add Anomaly\",\n",
    "    disabled=False,\n",
    "    button_style=\"info\",\n",
    "    tooltip=\"Click me\",\n",
    "    icon=\"plus-square\",\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "removeAnomalyButt = widgets.Button(\n",
    "    description=\"Remove Anomaly\",\n",
    "    disabled=False,\n",
    "    button_style=\"danger\",\n",
    "    tooltip=\"Click me\",\n",
    "    icon=\"plus-square\",\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "# File Upload Grid\n",
    "file_upload = widgets.FileUpload(\n",
    "    accept=\".xlsx\",\n",
    "    disabled=False,\n",
    "    multiple=True,\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "filename = '\"asdfgsadgfasdg\"'\n",
    "filename2 = '\"FHRSasdfte\"'\n",
    "\n",
    "FileTemplateClickWidget = widgets.HTML(\n",
    "    f\"<a href={filename} download={filename2}>Download Template</a>\"\n",
    ")\n",
    "\n",
    "loadBulkDataButt = widgets.Button(\n",
    "    description=\"LoadData\",\n",
    "    disabled=False,\n",
    "    button_style=\"info\",\n",
    "    tooltip=\"Click me\",\n",
    "    icon=\"check\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "runBulkDataButt = widgets.Button(\n",
    "    description=\"Run Test\",\n",
    "    disabled=False,\n",
    "    button_style=\"info\",\n",
    "    tooltip=\"Click me\",\n",
    "    icon=\"check\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"auto\", height=\"auto\"),\n",
    ")\n",
    "\n",
    "\n",
    "# error widget:\n",
    "errorWid = widgets.Valid(\n",
    "    value=False,\n",
    "    description=\"Valid!\",\n",
    "    style=genStyle_1,\n",
    "    disabled=False,\n",
    "    layout=Layout(width=\"auto\", height=\"auto\", align_items=\"stretch\"),\n",
    ")\n",
    "\n",
    "errorCloseButton = widgets.Button(\n",
    "    description=\"Close\",\n",
    "    disabled=False,\n",
    "    button_style=\"warning\",\n",
    "    tooltip=\"Click me\",\n",
    "    icon=\"times\",\n",
    "    style=genStyle_1,\n",
    "    layout=Layout(width=\"auto\", height=\"auto\", align_items=\"stretch\"),\n",
    ")\n",
    "box_layout = Layout(\n",
    "    display=\"flex\", flex_flow=\"row\", align_items=\"stretch\", border=\"solid\", width=\"100%\"\n",
    ")\n",
    "errorMessWidget = widgets.HBox([errorWid, errorCloseButton], layout=box_layout)\n",
    "progressOutput = widgets.Output(layout={\"border\": \"1px solid black\"})\n",
    "\n",
    "QgridManualTbleWidget = widgets.HBox([widgets.HBox([qgrid.show_grid(pd.DataFrame())])])\n",
    "QgridUploadTbleWidget = widgets.HBox([widgets.HBox([qgrid.show_grid(pd.DataFrame())])])\n",
    "QgridAnomalyTbleWidget = widgets.HBox([widgets.HBox([qgrid.show_grid(pd.DataFrame())])])\n",
    "\n",
    "\n",
    "url = \"\"\n",
    "urlClickWidget = widgets.HTML(\n",
    "    f\"<a href={url} target='_blank'>Click to Open Workbook</a>\"\n",
    ")\n",
    "urlBulk = \"\"\n",
    "urlClickBulkWidget = widgets.HTML(\n",
    "    f\"<a href={url} target='_blank'>Click to Open Workbook</a>\"\n",
    ")\n",
    "\n",
    "\n",
    "global TBRows\n",
    "global anomFormStart\n",
    "global gridNumOfRows\n",
    "global gridNumofColumns\n",
    "global progressBar\n",
    "\n",
    "TBRows = 0\n",
    "anomFormStart = 15\n",
    "gridNumOfRows = 24\n",
    "gridNumofColumns = 12\n",
    "\n",
    "progressBar = widgets.FloatProgress(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=10.0,\n",
    "    description=\"Loading:\",\n",
    "    bar_style=\"info\",\n",
    "    style={\"bar_color\": \"#ffff00\"},\n",
    "    orientation=\"horizontal\",\n",
    ")\n",
    "\n",
    "\n",
    "# Manual Upload Grid\n",
    "manualGrid = GridspecLayout(gridNumOfRows, gridNumofColumns, height=\"850px\")\n",
    "# manualGrid[RowStart:RowEnd, ColumnStart:ColumnEnd]\n",
    "manualGrid[0:1, 0:2] = investigationDateStartSelect\n",
    "manualGrid[0:1, 2:4] = investigationDateEndSelect\n",
    "manualGrid[1:2, 0:2] = piTag_tb\n",
    "manualGrid[1:2, 2:3] = site_DD\n",
    "manualGrid[2:3, 0:2] = RunStatusTag_tb\n",
    "\n",
    "manualGrid[2:3, 2:3] = RunStatusOperator_DD\n",
    "manualGrid[2:3, 3:4] = RunStatusValue_tb\n",
    "manualGrid[3:13, 0:4] = TestToRun_STB\n",
    "\n",
    "manualGrid[0:1, 7:10] = ModelSettingLabel\n",
    "manualGrid[0:1, 11:12] = StepsLabel\n",
    "manualGrid[1:2, 5:10] = WindowSizeSldr\n",
    "manualGrid[1:2, 10:12] = WindowSizeStepSldr\n",
    "manualGrid[2:3, 5:10] = WindowFreqSldr\n",
    "manualGrid[2:3, 10:12] = WindowFreqStepSldr\n",
    "manualGrid[3:4, 5:7] = StdDevCountHiSldr\n",
    "manualGrid[3:4, 10:12] = StdDevCountHiStepSldr\n",
    "manualGrid[3:4, 8:10] = StdDevCountLoSldr\n",
    "\n",
    "manualGrid[4:5, 5:10] = DeadbandSldr\n",
    "manualGrid[4:5, 10:12] = DeadbandStepSldr\n",
    "manualGrid[5:6, 5:10] = StartUpLagSldr\n",
    "manualGrid[5:6, 10:12] = StartUpLagStepSldr\n",
    "manualGrid[6:7, 5:10] = MinChangeSldr\n",
    "manualGrid[6:7, 10:12] = MinChangeStepSldr\n",
    "manualGrid[7:8, 5:10] = FixedLimHISldr\n",
    "manualGrid[7:8, 10:12] = FixedLimHIStepSldr\n",
    "manualGrid[8:9, 5:10] = FixedLimLOSldr\n",
    "manualGrid[8:9, 10:12] = FixedLimLOStepSldr\n",
    "manualGrid[9:10, 5:10] = outOfBoundsHiSldr\n",
    "manualGrid[9:10, 10:12] = outOfBoundsHiStepSldr\n",
    "manualGrid[10:11, 5:10] = outOfBoundsLoSldr\n",
    "manualGrid[10:11, 10:12] = outOfBoundsLoStepSldr\n",
    "manualGrid[11:12, 5:10] = DurationSldr\n",
    "manualGrid[11:12, 10:12] = DurationStepSldr\n",
    "manualGrid[12:13, 5:10] = ForecastDurationSldr\n",
    "manualGrid[12:13, 10:12] = ForecastDurationStepSldr\n",
    "manualGrid[13:14, 5:10] = DaysToLimTargetSldr\n",
    "manualGrid[13:14, 10:12] = DaysToLimTypeDD\n",
    "manualGrid[14:15, 5:7] = DaysToLimSigTB\n",
    "manualGrid[14:15, 8:10] = forcastLimWindowStart\n",
    "manualGrid[14:15, 10:12] = forcastLimWindowEnd\n",
    "\n",
    "manualGrid[11:12, 4:5] = AddAnomalyButt\n",
    "manualGrid[12:13, 4:5] = removeAnomalyButt\n",
    "\n",
    "manualGrid[13:14, 0:2] = manualLoadButt\n",
    "manualGrid[13:14, 2:4] = manualClearButt\n",
    "manualGrid[14:15, 0:4] = manualTestButt\n",
    "\n",
    "manualGrid[16:24, 5:12] = QgridManualTbleWidget\n",
    "manualGrid[16:17, 4:5] = urlClickWidget\n",
    "\n",
    "fileGrid = GridspecLayout(gridNumOfRows, gridNumofColumns, height=\"850px\")\n",
    "fileGrid[0:1, 0:3] = file_upload\n",
    "fileGrid[0:1, 3:5] = FileTemplateClickWidget\n",
    "fileGrid[1:2, 0:5] = loadBulkDataButt\n",
    "fileGrid[2:3, 0:12] = runBulkDataButt\n",
    "\n",
    "fileGrid[3:4, 0:5] = urlClickBulkWidget\n",
    "fileGrid[4:12, 0:12] = QgridUploadTbleWidget\n",
    "fileGrid[13:23, 0:12] = QgridAnomalyTbleWidget\n",
    "\n",
    "\n",
    "progressBar.layout.visibility = \"hidden\"\n",
    "errorMessWidget.layout.visibility = \"hidden\"\n",
    "urlClickWidget.layout.visibility = \"hidden\"\n",
    "urlClickBulkWidget.layout.visibility = \"hidden\"\n",
    "QgridManualTbleWidget.layout.visibility = \"hidden\"\n",
    "QgridUploadTbleWidget.layout.visibility = \"hidden\"\n",
    "QgridAnomalyTbleWidget.layout.visibility = \"hidden\"\n",
    "runBulkDataButt.disabled = True\n",
    "\n",
    "accordion = widgets.Accordion(children=[manualGrid, fileGrid], selected_index=0)\n",
    "headerWarningProgress = TwoByTwoLayout(\n",
    "    bottom_left=errorMessWidget, bottom_right=progressBar\n",
    ")\n",
    "\n",
    "mainForm = AppLayout(\n",
    "    header=headerWarningProgress,\n",
    "    left_sidebar=None,\n",
    "    center=accordion,\n",
    "    right_sidebar=None,\n",
    "    footer=progressOutput,\n",
    "    pane_heights=[0.2, 5, 0.5],\n",
    ")\n",
    "\n",
    "accordion.set_title(0, \"Manual Upload\")\n",
    "accordion.set_title(1, \"File Upload\")\n",
    "\n",
    "# **************User Input Display Code: END**************\n",
    "\n",
    "\n",
    "# **************Button Click Functions: Start**************\n",
    "\n",
    "\n",
    "def error_Close_Button(b):\n",
    "    #     Purpose: Close error message\n",
    "    #     Parameters: button widget\n",
    "    #     Returns: N/A\n",
    "    errorMessWidget.layout.visibility = \"hidden\"\n",
    "\n",
    "\n",
    "def run_addRowTest_butt(b):\n",
    "    #     Purpose: #Addas row for anomaly input on form\n",
    "    #     Parameters: button widget\n",
    "    #     Returns: N/A\n",
    "    global TBRows\n",
    "    leftBoxLst = []\n",
    "    right_boxlst = []\n",
    "\n",
    "    if TBRows < (gridNumOfRows - anomFormStart):\n",
    "        centerLst = [\n",
    "            ipydatetime.DatetimePicker(\n",
    "                description=\"Anomaly Start\",\n",
    "                disabled=False,\n",
    "                style={\"description_width\": \"initial\"},\n",
    "            )\n",
    "        ]\n",
    "        rightBoxLst = [\n",
    "            ipydatetime.DatetimePicker(\n",
    "                description=\"Anomaly End\",\n",
    "                disabled=False,\n",
    "                style={\"description_width\": \"initial\"},\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        center_box = widgets.VBox(centerLst)\n",
    "        right_box = widgets.VBox(rightBoxLst)\n",
    "\n",
    "        startRow = anomFormStart + TBRows\n",
    "        endRow = (anomFormStart + 1) + TBRows\n",
    "\n",
    "        manualGrid[startRow:endRow, 0:4] = widgets.HBox([center_box, right_box])\n",
    "        TBRows = TBRows + 1\n",
    "\n",
    "\n",
    "def run_removeRowTest_butt(b):\n",
    "    #     Purpose: #Remove row for anomaly input on form\n",
    "    #     Parameters: button widget\n",
    "    #     Returns: N/A\n",
    "    global TBRows\n",
    "    if TBRows >= 1:\n",
    "        startRow = (anomFormStart - 1) + TBRows\n",
    "        endRow = anomFormStart + TBRows\n",
    "\n",
    "        manualGrid[startRow:endRow, 0:4] = widgets.HBox([])\n",
    "        TBRows = TBRows - 1\n",
    "\n",
    "\n",
    "# **********manual Load Form Buttons**********\n",
    "def run_manualLoad_butt(b):\n",
    "    #     Purpose: Loads user inputs on screen to Qgrid for user to see what models will be build\n",
    "    #     Parameters: button Widget\n",
    "    #     Returns: N/A\n",
    "    error_Close_Button(\"\")\n",
    "    # get info and data to populate and load qgrid\n",
    "    get_manual_input_load_qgrid()\n",
    "    manualClearButt.disabled = False\n",
    "    manualTestButt.disabled = False\n",
    "\n",
    "\n",
    "def run_manualClear_butt(b):\n",
    "    #     Purpose: Clear screen if user needs to change onscreen info before running program\n",
    "    #     Parameters:\n",
    "    #     Returns: N/A\n",
    "    error_Close_Button(\"\")\n",
    "    QgridManualTbleWidget.layout.visibility = \"hidden\"\n",
    "    manualTestButt.disabled = True\n",
    "    manualClearButt.disabled = True\n",
    "    urlClickWidget.layout.visibility = \"hidden\"\n",
    "    progressOutput.clear_output()\n",
    "\n",
    "\n",
    "def run_manualTest_butt(b):\n",
    "    #     Purpose: Main function to run program when user inputs all info manually on form\n",
    "    #     Parameters: widget run_manualTest_butt ID\n",
    "    #     Returns: N/A\n",
    "    try:\n",
    "        userInputManualFlag = True\n",
    "        run_program(userInputManualFlag, anomFormStart, \"\", \"\")\n",
    "    except Exception as ex:\n",
    "        pop_up(str(ex))\n",
    "\n",
    "    finally:\n",
    "        loading_overlay(False)\n",
    "        progressBar.layout.visibility = \"hidden\"\n",
    "\n",
    "\n",
    "# **********Bulk Load Form Buttons**********\n",
    "def load_bulkData_butt(b):\n",
    "    #     Purpose: loads data from bulk load excel sheet to screen for user to view befor running\n",
    "    #     Parameters: widget button\n",
    "    #     Returns: N/A\n",
    "    global bulkUploadUserData\n",
    "    global AnomalyInputData\n",
    "    error_Close_Button(\"\")\n",
    "\n",
    "    # get data from file\n",
    "    if len(file_upload.value.values()) <= 0:\n",
    "        pop_up(\"Must Add File\")\n",
    "        return \"\"\n",
    "\n",
    "    if len(file_upload.value.values()) > 1:\n",
    "        pop_up(\"Can Upload One File\")\n",
    "        return \"\"\n",
    "\n",
    "    uploaded_file = list(file_upload.value.values())[0]\n",
    "    fileName = uploaded_file[\"metadata\"][\"name\"]\n",
    "    content = uploaded_file[\"content\"]\n",
    "    if \".xlsx\" not in fileName.lower():\n",
    "        pop_up(\"Must be .xlsx File\")\n",
    "        return \"\"\n",
    "\n",
    "    try:\n",
    "        # Read main data file and put into dataFrame\n",
    "        bulkUploadUserData = pd.read_excel(\n",
    "            content, index_col=None, skiprows=0, header=0\n",
    "        )\n",
    "\n",
    "        # Read anomaly data file and put into dataFrame\n",
    "        AnomalyInputData = pd.read_excel(\n",
    "            content, sheet_name=\"sheet2\", index_col=None, skiprows=0, header=0\n",
    "        )\n",
    "\n",
    "        # load Qgrid on user interface\n",
    "        qgridAnomaly = load_Anomaly_qgrid(AnomalyInputData)\n",
    "        lst = list(QgridAnomalyTbleWidget.children[0].children)\n",
    "        lst[0] = qgridAnomaly\n",
    "        QgridAnomalyTbleWidget.children[0].children = lst\n",
    "        QgridAnomalyTbleWidget.layout.visibility = \"visible\"\n",
    "\n",
    "    except:\n",
    "        pop_up(\"ERROR WITH LOADING EXCEL SHEET: PLEASE DOWNLOAD TEMPLATE AND FOLLOW\")\n",
    "        AnomalyInputData = \"\"\n",
    "        return \"\"\n",
    "\n",
    "    # load Qgrid on user interface\n",
    "    qgridUpload = load_bulkData_qgrid(bulkUploadUserData)\n",
    "    remove_replace_grid(QgridUploadTbleWidget, qgridUpload)\n",
    "    runBulkDataButt.disabled = False\n",
    "\n",
    "\n",
    "def run_bulkData_butt(b):\n",
    "    #     Purpose: Main function to run program from user bulk load data\n",
    "    #     Parameters: widget button\n",
    "    #     Returns: N/A\n",
    "    try:\n",
    "        global UpdatedbulkUploadUserData\n",
    "        global qgridUpload\n",
    "\n",
    "        UpdatedbulkUploadUserData = pd.DataFrame()\n",
    "        userInputManualFlag = False\n",
    "        # get any updated Qgrid values\n",
    "        UpdatedbulkUploadUserData = qgridUpload.get_changed_df()\n",
    "        # run program\n",
    "        run_program(\n",
    "            userInputManualFlag, \"\", UpdatedbulkUploadUserData, AnomalyInputData\n",
    "        )\n",
    "    except Exception as ex:\n",
    "        pop_up(str(ex))\n",
    "\n",
    "    finally:\n",
    "        loading_overlay(False)\n",
    "        progressBar.layout.visibility = \"hidden\"\n",
    "\n",
    "\n",
    "errorCloseButton.on_click(error_Close_Button)\n",
    "AddAnomalyButt.on_click(run_addRowTest_butt)\n",
    "removeAnomalyButt.on_click(run_removeRowTest_butt)\n",
    "manualLoadButt.on_click(run_manualLoad_butt)\n",
    "manualClearButt.on_click(run_manualClear_butt)\n",
    "manualTestButt.on_click(run_manualTest_butt)\n",
    "loadBulkDataButt.on_click(load_bulkData_butt)\n",
    "runBulkDataButt.on_click(run_bulkData_butt)\n",
    "\n",
    "\n",
    "# **************Button Click Functions: End**************\n",
    "\n",
    "\n",
    "def remove_replace_grid(qgridWidget, dfToLoad):\n",
    "    # remove existing Qgrid onscreen and replace with upated one\n",
    "    lst = list(qgridWidget.children[0].children)\n",
    "    lst[0] = dfToLoad\n",
    "    qgridWidget.children[0].children = lst\n",
    "    qgridWidget.layout.visibility = \"visible\"\n",
    "\n",
    "\n",
    "def update_wb_url(urlWidget, newUrl):\n",
    "    url = newUrl\n",
    "    urlWidget.value = f\"<a href={url} target='_blank'>Click to Open Workbook</a>\"\n",
    "    urlWidget.layout.visibility = \"visible\"\n",
    "\n",
    "\n",
    "def run_program(\n",
    "    userInputManualFlag, anomFormStart, UpdatedbulkUploadUserData, AnomalyInputData\n",
    "):\n",
    "    #     Purpose: calls all needed functions to run program, both manual and bulk load inputs call this function\n",
    "    #     Parameters: userInputManualFlag: bool, True = user data from manual input screen: False=bulk load\n",
    "    #                 anomFormStart: int: tracks where anonally input dates start in manual grid(ipwidgts). needed for\n",
    "    #                                 pulling anomaly dates from screen\n",
    "    #                 UpdatedbulkUploadUserData: pandas DataFrame. Data from bulk load button\n",
    "    #                 AnomalyInputData: Pandas DataFrame: data from bulk load screen\n",
    "    #     Returns: N/A\n",
    "    #     try:\n",
    "    global Equipment\n",
    "    global Models\n",
    "    global CapsulesResults\n",
    "    global accordion\n",
    "\n",
    "    QgridManualTbleWidget.layout.visibility = \"hidden\"\n",
    "    QgridAnomalyTbleWidget.layout.visibility = \"hidden\"\n",
    "    QgridUploadTbleWidget.layout.visibility = \"hidden\"\n",
    "    urlClickWidget.layout.visibility = \"hidden\"\n",
    "    urlClickBulkWidget.layout.visibility = \"hidden\"\n",
    "    progressBar.layout.visibility = \"visible\"\n",
    "    error_Close_Button(\"\")\n",
    "    loading_overlay(True)\n",
    "\n",
    "    progressBar.value = 2\n",
    "\n",
    "    #     with progressOutput:\n",
    "    userInputs, Equipment, Models, CapsulesResults = bild_objects(\n",
    "        userInputManualFlag, anomFormStart, UpdatedbulkUploadUserData, AnomalyInputData\n",
    "    )\n",
    "    #     progressOutput.clear_output()\n",
    "\n",
    "    progressBar.value = 10\n",
    "    progressBar.layout.visibility = \"hidden\"\n",
    "\n",
    "    if any(userInputs):\n",
    "        if not Equipment == \"\":\n",
    "            if not Models == \"\":\n",
    "                if not CapsulesResults.capsuleTable.empty:\n",
    "                    if userInputManualFlag:\n",
    "                        # remove existing Qgrid onscreen and replace with upated one\n",
    "                        remove_replace_grid(\n",
    "                            QgridManualTbleWidget, CapsulesResults.finalSumTble_Qgrid\n",
    "                        )\n",
    "                    else:\n",
    "                        remove_replace_grid(\n",
    "                            QgridUploadTbleWidget, CapsulesResults.finalSumTble_Qgrid\n",
    "                        )\n",
    "                else:\n",
    "                    pop_up(\"NO WERE FOUND CAPSAULS\")\n",
    "                # set URl Link\n",
    "                if userInputManualFlag:\n",
    "                    update_wb_url(\n",
    "                        urlClickWidget,\n",
    "                        Models.PushedResultsOrginalList[0].spy.workbook_url,\n",
    "                    )\n",
    "                else:\n",
    "                    update_wb_url(\n",
    "                        urlClickBulkWidget,\n",
    "                        Models.PushedResultsOrginalList[0].spy.workbook_url,\n",
    "                    )\n",
    "    # Remove Overlay\n",
    "    loading_overlay(False)\n",
    "\n",
    "\n",
    "# Display User Input Screen:\n",
    "mainForm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749f4df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Classes\n",
    "class MissingInputError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class WrongInputDataError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class NormalizeDateError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class SeeqSpyError(Exception):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "327ad80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***********General Functions***********\n",
    "\n",
    "\n",
    "def bild_objects(\n",
    "    userInputManualFlag, anomFormStart, UpdatedbulkUploadUserData, AnomalyInputData\n",
    "):\n",
    "    #     Purpose:\n",
    "    #     Parameters: userInputs: Pandas DataFrame: formated data from user on pi tags, anomalies and tests to build\n",
    "    #                 workbookFolder: String: folder to save models when built\n",
    "    #                 anomFormStart: int: tracks where anonally input dates start in manual grid(ipwidgts). needed for\n",
    "    #                                 pulling anomaly dates from screen\n",
    "    #                 UpdatedbulkUploadUserData: pandas DataFrame. Data from bulk load button\n",
    "    #                 AnomalyInputData: Pandas DataFrame: data from bulk load screen\n",
    "    #     Returns: Equipment: Class for all information about user inputs, tags, and tests to be made\n",
    "    #             Models: class for Builds/pushes all models to seeq\n",
    "    #             CapsulesResults: class for Evaluates models that were built and calculates capsules found\n",
    "    global userInputs\n",
    "    global Equipment\n",
    "    global Models\n",
    "    global CapsulesResults\n",
    "\n",
    "    # Window for what is considered a catch: true possitive. +- added to start and end date of anomaly time\n",
    "    anomalyCatchWindow = pd.Timedelta(days=0, hours=1, minutes=0, seconds=0)\n",
    "    workbookFolder = (\n",
    "        f'Anomaly DetectiodfaDT_{datetime.now().strftime(\"%m/%d/%Y %H:%M:%S\")}'\n",
    "    )\n",
    "\n",
    "    userInputs = format_user_inputs(\n",
    "        userInputManualFlag, anomFormStart, UpdatedbulkUploadUserData, AnomalyInputData\n",
    "    )\n",
    "\n",
    "    if not any(userInputs):\n",
    "        raise MissingInputError(\"No User Input Found\")\n",
    "\n",
    "    # Initialize Equipment: Get data for each piTag/signal to build models/Tesing Technique:\n",
    "    Equipment = EquipmentSignals(userInputs)\n",
    "\n",
    "    if Equipment.SignalDB.empty:\n",
    "        raise MissingInputError(\"NO equipment was found\")\n",
    "\n",
    "    progressBar.value = 4\n",
    "\n",
    "    # Build Modeling Techniques and deploy to workbook:\n",
    "    Models = ModelingTechnique(workbookFolder, Equipment.SignalDB)\n",
    "\n",
    "    if Models.pushedResults.empty:\n",
    "        raise MissingInputError(\"No spy.Pushed Results Found\")\n",
    "\n",
    "    progressBar.value = 7\n",
    "\n",
    "    # create Capsule Object and Evaluate capsules generated for each Modeling Technique:\n",
    "    CapsulesResults = Capsules(\n",
    "        Equipment.SignalDB, Models.pushedResults, anomalyCatchWindow\n",
    "    )\n",
    "\n",
    "    return (userInputs, Equipment, Models, CapsulesResults)\n",
    "\n",
    "\n",
    "def format_user_inputs(\n",
    "    userInputManualFlag, anomFormStart, UpdatedbulkUploadUserData, AnomalyInputData\n",
    "):\n",
    "    #     Purpose: Data Varification / manipulation for all user inputs into dataframe.\n",
    "    #     Parameters: userInputManual: true if user supplied manual data from form, False if user uploaded info by file\n",
    "    #                 anomFormStart: int: tracks where anonally input dates start in manual grid(ipwidgts). needed for\n",
    "    #                                 pulling anomaly dates from screen\n",
    "    #                 UpdatedbulkUploadUserData: pandas DataFrame. Data from bulk load button\n",
    "    #                 AnomalyInputData: Pandas DataFrame: data from bulk load screen\n",
    "    #     Returns: data frame of requried information for program\n",
    "    #                 dataFrame to hold user inputs\n",
    "\n",
    "    userData = pd.DataFrame()\n",
    "    # dict to hold anomaly dates\n",
    "    knownAnomalies = {}\n",
    "    startDateInput = \"\"\n",
    "    endDateInput = \"\"\n",
    "\n",
    "    if userInputManualFlag:\n",
    "        # check that user fields are good\n",
    "        startDateInput = normalize_date_time(investigationDateStartSelect.value)\n",
    "        endDateInput = normalize_date_time(investigationDateEndSelect.value)\n",
    "        if startDateInput > endDateInput:\n",
    "            raise WrongInputDataError(\"Start Date Must Not Come After End Date\")\n",
    "\n",
    "        # check for piTag\n",
    "        if not piTag_tb.value:\n",
    "            raise MissingInputError(\"Must Have PiTag\")\n",
    "\n",
    "        # Format and validate data for ANOMALY DATES, return emtpy string if values are bad\n",
    "        if TBRows > 0:  # TB rows Counts number of anomaly dates added to form\n",
    "            knownAnomalies = get_anomaly_ranges(\n",
    "                anomFormStart, startDateInput, endDateInput, \"\"\n",
    "            )\n",
    "\n",
    "        # Reformat/shorten TestToRun_STB lists spy.push cannot handle long name (this is the name that will get pushed to WB)\n",
    "        TestToRun_Lst = [x.split(\":\", 1)[0] for x in TestToRun_STB.value]\n",
    "\n",
    "        # Format and validate data for different TEST VARIATIONS\n",
    "        formatTestVariations = format_test_Variations(\n",
    "            TestToRun_Lst, userInputManualFlag, \"\"\n",
    "        )\n",
    "\n",
    "        # get and validate runstatus: need to set to null if '' for function to work for manual and bulk load\n",
    "        RunStatusTag = RunStatusTag_tb.value\n",
    "        if RunStatusTag == \"\":\n",
    "            RunStatusTag = np.NaN\n",
    "        runStatusSig, runStatOpera, runStatVal = validate_runstatus_input(\n",
    "            RunStatusTag,\n",
    "            runStatOpera=RunStatusOperator_DD.value,\n",
    "            runStatVal=RunStatusValue_tb.value,\n",
    "        )\n",
    "\n",
    "        userData = pd.DataFrame(\n",
    "            {\n",
    "                \"startDate\": pd.Timestamp(investigationDateStartSelect.value),\n",
    "                \"endDate\": pd.Timestamp(investigationDateEndSelect.value),\n",
    "                \"piTag\": piTag_tb.value,\n",
    "                \"site\": site_DD.value,\n",
    "                \"runStatusTag\": runStatusSig,\n",
    "                \"runStatusCondition\": f\"{runStatOpera}{runStatVal}\",\n",
    "                \"testMethods\": [TestToRun_Lst],\n",
    "                \"testVariations\": [formatTestVariations],\n",
    "                \"knownAnomalies\": [knownAnomalies],\n",
    "            },\n",
    "            index=[0],\n",
    "        )\n",
    "\n",
    "    else:  # get data from Bulk Upload\n",
    "        # get unique values of all piTags that the tags used. loop through each for spy.pull\n",
    "        piTagsUniqueLst = UpdatedbulkUploadUserData.PiTag.unique()\n",
    "\n",
    "        # loop each unique tag getting data to build userinfo DataFrame\n",
    "        # Program will put all variation for the unique pi tag in one list within one cell of dataframe\n",
    "        for piTag in range(len(piTagsUniqueLst)):\n",
    "            # Get all rows(ie.variations) for current PiTag\n",
    "            mask = UpdatedbulkUploadUserData[\"PiTag\"].values == piTagsUniqueLst[piTag]\n",
    "            piTagRowsdf = UpdatedbulkUploadUserData[mask].copy()\n",
    "            piTagRowsdf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            # validate and noarmalize Investigation Dates;\n",
    "            if not any(piTagRowsdf[\"InvestigationStartDate\"]) or not any(\n",
    "                piTagRowsdf[\"InvestigationEndDate\"]\n",
    "            ):\n",
    "                raise MissingInputError(\n",
    "                    \"Must InvestigationStartDate and InvestigationEndDate\"\n",
    "                )\n",
    "\n",
    "            # Note: select top dates for start and end date. All dates for unique pi tag need be to same\n",
    "            piTagRowsdf.loc[:, \"InvestigationStartDate\"] = normalize_date_time(\n",
    "                piTagRowsdf[\"InvestigationStartDate\"]\n",
    "            )\n",
    "            piTagRowsdf.loc[:, \"InvestigationEndDate\"] = normalize_date_time(\n",
    "                piTagRowsdf[\"InvestigationEndDate\"]\n",
    "            )\n",
    "            startDateInput = piTagRowsdf.loc[0, \"InvestigationStartDate\"]\n",
    "            endDateInput = piTagRowsdf.loc[0, \"InvestigationEndDate\"]\n",
    "            if startDateInput > endDateInput:\n",
    "                raise WrongInputDataError(\"Start Date Must Not Come After End Date\")\n",
    "\n",
    "            # Get unique list of tests that need to be run for this piTag\n",
    "            TestToRun_Lst = list(piTagRowsdf.TestsToRun.unique())\n",
    "            # Format and validate data for TEST VARIATIONS\n",
    "            formatTestVariations = format_test_Variations(\n",
    "                TestToRun_Lst, userInputManualFlag, piTagRowsdf\n",
    "            )\n",
    "\n",
    "            # ANOMALLIES: get any anomally dates from for current piTag\n",
    "            currentAnomaly = pd.DataFrame()\n",
    "            if any(AnomalyInputData):\n",
    "                # get all anomalies for current piTag\n",
    "                currentAnomaly = AnomalyInputData.loc[\n",
    "                    AnomalyInputData[\"PiTag\"] == piTagsUniqueLst[piTag]\n",
    "                ]\n",
    "                currentAnomaly.reset_index(drop=True, inplace=True)\n",
    "            # Format and validate data for ANOMALY DATES, return emtpy string if values are bad\n",
    "            if any(currentAnomaly):\n",
    "                knownAnomalies = get_anomaly_ranges(\n",
    "                    anomFormStart, startDateInput, endDateInput, currentAnomaly\n",
    "                )\n",
    "\n",
    "            # get and validate runstatus: All runstatus for unique pi tag need be to same\n",
    "            runStatusSig, runStatOpera, runStatVal = validate_runstatus_input(\n",
    "                piTagRowsdf[\"RunningPiTag\"][0],\n",
    "                piTagRowsdf[\"RunningOperator\"][0],\n",
    "                piTagRowsdf[\"RunningValue\"][0],\n",
    "            )\n",
    "            #                 if runStatusSig == 'ERROR':\n",
    "            #                     return ''\n",
    "\n",
    "            # Add all user inputs to dataframe\n",
    "            curRow = pd.DataFrame(\n",
    "                {\n",
    "                    \"fdg\": startDateInput,\n",
    "                    \"endDate\": endDateInput,\n",
    "                    \"f\": piTagRowsdf[\"PiTag\"][0],\n",
    "                    \"site\": piTagRowsdf[\"Site\"][0],\n",
    "                    \"runStatusTag\": runStatusSig,\n",
    "                    \"runStatusCondition\": f\"{runStatOpera}{runStatVal}\",\n",
    "                    \"testMethods\": [TestToRun_Lst],\n",
    "                    \"b\": historian_lookup(piTagRowsdf[\"Site\"][0]),\n",
    "                    \"testVariafbations\": [formatTestVariations],\n",
    "                    \"knownAnomalies\": [knownAnomalies],\n",
    "                },\n",
    "                index=[0],\n",
    "            )\n",
    "\n",
    "            userData = pd.concat([userData, curRow], axis=0)\n",
    "            userData.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return userData\n",
    "\n",
    "\n",
    "def validate_runstatus_input(runStatusSig, runStatOpera, runStatVal):\n",
    "\n",
    "    # RUN STATUS: Format runstatus. if no runstatus given make signal that is always true. All runstatus for unique pi tag need be to same\n",
    "    if pd.isnull(runStatusSig):\n",
    "        rstatusSig = \"1\"\n",
    "        rstatOpera = \"==\"\n",
    "        rstatVal = \"1\"\n",
    "    else:\n",
    "        # set runstatus signal tag\n",
    "        rstatusSig = runStatusSig\n",
    "\n",
    "        # check run status operator\n",
    "        if not runStatOpera in [\">\", \"==\", \"~=\", \"<\"]:\n",
    "            if runStatOpera == \"=\":\n",
    "                rstatOpera = \"==\"\n",
    "            else:\n",
    "                raise WrongInputDataError(\"ERROR Run Status Operator not Correct\")\n",
    "\n",
    "        else:\n",
    "            rstatOpera = runStatOpera\n",
    "\n",
    "        # check and format Run status value #if runstatus is letters seeq will need quotes\n",
    "        if str(runStatVal) == \"\":\n",
    "            raise MissingInputError(\n",
    "                \"Must Have runstatus value or remove runstatus pi Tag\"\n",
    "            )\n",
    "\n",
    "        rstatVal = runStatVal\n",
    "        rsTemp = str(runStatVal).split(\".\")[0]\n",
    "        if not str(rsTemp).isnumeric():\n",
    "            rstatVal = f'\"{runStatVal}\"'\n",
    "\n",
    "    return rstatusSig, rstatOpera, rstatVal\n",
    "\n",
    "\n",
    "def format_test_Variations(TestToRun_Lst, isManualUpload, BulkUploadData):\n",
    "    #     Purpose: Format all test variations perameters defined by user\n",
    "    #     Parameters: TestToRun_Lst: list of tests,\n",
    "    #                  isManualUpload: True get data from form, False get data from DataFrame\n",
    "    #                  BulkUploadData: pandas DataFrame. Data from bulk load button\n",
    "    #     Returns: Dictionary of perameters for different tests to be created\n",
    "    if isManualUpload:\n",
    "\n",
    "        # Get values from User input Form and put into dictionary: loop for sliders to get all values\n",
    "        WindowSize = list(\n",
    "            range(\n",
    "                WindowSizeSldr.value[0],\n",
    "                WindowSizeSldr.value[-1] + WindowSizeStepSldr.value,\n",
    "                WindowSizeStepSldr.value,\n",
    "            )\n",
    "        )\n",
    "        WindowFreq = list(\n",
    "            range(\n",
    "                WindowFreqSldr.value[0],\n",
    "                WindowFreqSldr.value[-1] + WindowFreqStepSldr.value,\n",
    "                WindowFreqStepSldr.value,\n",
    "            )\n",
    "        )\n",
    "        StdDevCountHi = list(\n",
    "            range(\n",
    "                StdDevCountHiSldr.value[0],\n",
    "                StdDevCountHiSldr.value[-1] + StdDevCountHiStepSldr.value,\n",
    "                StdDevCountHiStepSldr.value,\n",
    "            )\n",
    "        )\n",
    "        StdDevCountLo = list(\n",
    "            range(\n",
    "                StdDevCountLoSldr.value[0],\n",
    "                StdDevCountLoSldr.value[-1] + StdDevCountHiStepSldr.value,\n",
    "                StdDevCountHiStepSldr.value,\n",
    "            )\n",
    "        )\n",
    "        Deadband = list(\n",
    "            range(\n",
    "                DeadbandSldr.value[0],\n",
    "                DeadbandSldr.value[-1] + DeadbandStepSldr.value,\n",
    "                DeadbandStepSldr.value,\n",
    "            )\n",
    "        )\n",
    "        StartUpLag = list(\n",
    "            range(\n",
    "                StartUpLagSldr.value[0],\n",
    "                StartUpLagSldr.value[-1] + StartUpLagStepSldr.value,\n",
    "                StartUpLagStepSldr.value,\n",
    "            )\n",
    "        )\n",
    "        MinChange = list(\n",
    "            range(\n",
    "                MinChangeSldr.value[0],\n",
    "                MinChangeSldr.value[-1] + MinChangeStepSldr.value,\n",
    "                MinChangeStepSldr.value,\n",
    "            )\n",
    "        )\n",
    "        FixedHiLim = list(\n",
    "            range(\n",
    "                FixedLimHISldr.value[0],\n",
    "                FixedLimHISldr.value[-1] + FixedLimHIStepSldr.value,\n",
    "                FixedLimHIStepSldr.value,\n",
    "            )\n",
    "        )\n",
    "        FixedLoLim = list(\n",
    "            range(\n",
    "                FixedLimLOSldr.value[0],\n",
    "                FixedLimLOSldr.value[-1] + FixedLimLOStepSldr.value,\n",
    "                FixedLimLOStepSldr.value,\n",
    "            )\n",
    "        )\n",
    "        outOfBoundsHi = list(\n",
    "            range(\n",
    "                outOfBoundsHiSldr.value[0],\n",
    "                outOfBoundsHiSldr.value[-1] + outOfBoundsHiStepSldr.value,\n",
    "                outOfBoundsHiStepSldr.value,\n",
    "            )\n",
    "        )\n",
    "        outOfBoundsLo = list(\n",
    "            range(\n",
    "                outOfBoundsLoSldr.value[0],\n",
    "                outOfBoundsLoSldr.value[-1] + outOfBoundsLoStepSldr.value,\n",
    "                outOfBoundsLoStepSldr.value,\n",
    "            )\n",
    "        )\n",
    "        Duration = list(\n",
    "            range(\n",
    "                DurationSldr.value[0],\n",
    "                DurationSldr.value[-1] + DurationStepSldr.value,\n",
    "                DurationStepSldr.value,\n",
    "            )\n",
    "        )\n",
    "        ForecastDuration = list(\n",
    "            range(\n",
    "                ForecastDurationSldr.value[0],\n",
    "                ForecastDurationSldr.value[-1] + ForecastDurationStepSldr.value,\n",
    "                ForecastDurationStepSldr.value,\n",
    "            )\n",
    "        )\n",
    "        forcastWindowStartDate = forcastLimWindowStart.value\n",
    "        forcastWindowEndDate = forcastLimWindowEnd.value\n",
    "\n",
    "    else:  # bulk upload\n",
    "        WindowSize = list(BulkUploadData.WindowSize.unique())\n",
    "        WindowFreq = list(BulkUploadData.WindowFreq.unique())\n",
    "        StdDevCountHi = list(BulkUploadData.StdDevCountHi.unique())\n",
    "        StdDevCountLo = list(BulkUploadData.StdDevCountLo.unique())\n",
    "\n",
    "        Deadband = list(BulkUploadData.Deadband.unique())\n",
    "        # seeq formula will error if deadband less than 1\n",
    "        if all(i < 1 for i in Deadband):\n",
    "            raise WrongInputDataError(\"Deadband cannot be lessthan 1\")\n",
    "\n",
    "        StartUpLag = list(BulkUploadData.StartUpLag.unique())\n",
    "        MinChange = list(BulkUploadData.MinChange.unique())\n",
    "        FixedHiLim = list(BulkUploadData.FixedHiLim.unique())\n",
    "        FixedLoLim = list(BulkUploadData.FixedLoLim.unique())\n",
    "        outOfBoundsHi = list(BulkUploadData.outOfBoundsHi.unique())\n",
    "        outOfBoundsLo = list(BulkUploadData.outOfBoundsLo.unique())\n",
    "        Duration = list(BulkUploadData.Duration.unique())\n",
    "        ForecastDuration = list(BulkUploadData.ForecastDuration.unique())\n",
    "        forcastWindowStartDate = BulkUploadData[\"forcastLimWindowStart\"][0]\n",
    "        forcastWindowEndDate = BulkUploadData[\"forcastLimWindowEnd\"][0]\n",
    "\n",
    "    # Data varification for FORCAST FIXED WINDOWstart and end dates\n",
    "    if (\n",
    "        \"Fosadfmit\" in TestToRun_Lst\n",
    "        or \"Forecasadfcore\" in TestToRun_Lst\n",
    "    ):\n",
    "        if not forcastWindowStartDate or not forcastWindowEndDate:\n",
    "            raise WrongInputDataError(\n",
    "                \"Forcaafsgend date\"\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            if forcastWindowStartDate > forcastWindowEndDate:\n",
    "                raise WrongInputDataError(\n",
    "                    \"ForasfgDate must be after End Date\"\n",
    "                )\n",
    "\n",
    "            if (forcastWindowEndDate - forcastWindowStartDate) == pd.Timedelta(days=0):\n",
    "                raise WrongInputDataError(\n",
    "                    \"Forcaerthg Date must at least 1 day before End Date\"\n",
    "                )\n",
    "\n",
    "    # Data varification for Days To Limit Dynamic Signal WINDOWstart and end dates\n",
    "    if (\n",
    "        \"Darthicthd\" in TestToRun_Lst\n",
    "        or \"Dastrhnamic-trhScore\" in TestToRun_Lst\n",
    "    ):\n",
    "        if DaysToLimSigTB.value == \"\":\n",
    "            raise MissingInputError(\"Dthgnal\")\n",
    "\n",
    "    # Add Required Units for test variations\n",
    "    gn = [str(x) + \"d\" for x in WindowFreq]\n",
    "    sadf = [str(x) + \"d\" for x in WindowSize]\n",
    "    asdf = [str(x) + \"min\" for x in Deadband]\n",
    "    gfdh = [str(x) + \"hr\" for x in StartUpLag]\n",
    "    sdfgn = [str(x) + \"d\" for x in Duration]\n",
    "    sdfn = [str(x) + \"week\" for x in ForecastDuration]\n",
    "\n",
    "    # Build Dict to add to equipment Dataframe\n",
    "    variationsDic = {\n",
    "        \"ZDX\": etrh,\n",
    "        \"sb\": erg,\n",
    "        \"wef\": thyjm,\n",
    "        \"eth\": rweg,\n",
    "        \"sadf\": erg,\n",
    "        \"Minfhange\": afsh,\n",
    "        \"asg\": asfg,\n",
    "        \"FixedwerLoLim\": afdh,\n",
    "        \"asd\": fdh,\n",
    "        \"df\": hreth,\n",
    "        \"DaysTsdf\": eth,\n",
    "        \"DaysTsdf\": asd,\n",
    "        \"DaysTsdf\": [sdf.value],\n",
    "        \"Dayssfype\": [asdf.value],\n",
    "        \"DaysTsdf\": [asdfg.value],\n",
    "        \"DaysTsdf\": [thstrehb],\n",
    "        \"forcastDaysTsdfLimWindowEnd\": [asg],\n",
    "    }\n",
    "\n",
    "    # find max lenght of input variations\n",
    "    max_key, max_value = max(variationsDic.items(), key=lambda x: len(set(x[1])))\n",
    "    maxLenth = len(max_value)\n",
    "\n",
    "    # make sure each perameter has the same amount of inputs. If not add perameters untill it they are equal\n",
    "    for key, value in variationsDic.items():\n",
    "        if len(value) < maxLenth:\n",
    "            for i in range(maxLenth - len(variationsDic[key])):\n",
    "                variationsDic[key].append(value[i])\n",
    "\n",
    "    return variationsDic\n",
    "\n",
    "\n",
    "def historian_lookup(site):\n",
    "    datasourceName = \"\"\n",
    "    if site == \"omkjm\":\n",
    "        datasourceName = \"asdfasdf\"\n",
    "    elif site == \"asdfeerrfg\":\n",
    "        datasourceName = \"dfghfdgh\"\n",
    "    elif site == \"qwer\":\n",
    "        datasourceName = \"osipi\"\n",
    "    elif site == \"asdf\":\n",
    "        datasourceName = \"dfghwert\"\n",
    "    elif site == \"wer\" or site == \"dfgh\":\n",
    "        datasourceName = \"dfghdfgh\"\n",
    "\n",
    "    return datasourceName\n",
    "\n",
    "\n",
    "def get_anomaly_ranges(anomFormStart, startDateInput, endDateInput, AnomalyInputData):\n",
    "    #     Purpose: Get and format all start and end dates for anomalies\n",
    "    #     Parameters: anonFormStart: integer of the row on main screen Grid (manualGrid) location where anomaly dates start\n",
    "    #                 startDateInput: Date:time: user input, start investigation date. used to Verify anomaly date is after\n",
    "    #                 endDateInput:Date:time: user input, End investigation date. used to Verify anomaly end date is before\n",
    "    #                 AnomalyInputData: pandas DataFrame: from bulk load screen (optional)\n",
    "    #     Returns: Dictionary of anomaly and whith start and end Date\n",
    "    knownAnomalies = {}\n",
    "\n",
    "    if not any(AnomalyInputData):  # anomaly dates from input form if needed\n",
    "        # create DF of anomaly dates\n",
    "        AnomalyInputData = pd.DataFrame()\n",
    "\n",
    "        # get length of widgets in row\n",
    "        LenMainGridRown = manualGrid.n_rows\n",
    "        formlength = len(manualGrid[anomFormStart, 1].children)\n",
    "\n",
    "        # get all anomaly dates from user form\n",
    "        for i in range(anomFormStart, LenMainGridRown + 1):\n",
    "            startDate = \"\"\n",
    "            endDate = \"\"\n",
    "            for ii in range(formlength):\n",
    "                curRow = pd.DataFrame()\n",
    "                try:\n",
    "                    cell = manualGrid[i, 1].children[ii].children[0]\n",
    "                except:\n",
    "                    break\n",
    "\n",
    "                if cell.description == \"Anomaly Start\":\n",
    "                    startDate = pd.to_datetime(cell.value)\n",
    "                    # normalize Start Date\n",
    "                    startDate = normalize_date_time(startDate)\n",
    "                    if not startDate:\n",
    "                        startDate = \"\"\n",
    "\n",
    "                if cell.description == \"Anomaly End\":\n",
    "                    endDate = pd.to_datetime(cell.value)\n",
    "                    # normalize End Date\n",
    "                    endDate = normalize_date_time(endDate)\n",
    "                    if not endDate:\n",
    "                        endDate = \"\"\n",
    "\n",
    "                curRow = curRow.append(\n",
    "                    {\"AnomalyStart\": startDate, \"AnomalyEnd\": endDate},\n",
    "                    ignore_index=True,\n",
    "                )\n",
    "\n",
    "            AnomalyInputData = pd.concat([AnomalyInputData, curRow], axis=0)\n",
    "            AnomalyInputData.reset_index(drop=True, inplace=True)\n",
    "        else:  # anomaly dates from file ie. AnomalyInputData\n",
    "            AnomalyInputData.loc[:, \"AnomalyStart\"] = normalize_date_time(\n",
    "                AnomalyInputData[\"AnomalyStart\"]\n",
    "            )\n",
    "            AnomalyInputData.loc[:, \"AnomalyEnd\"] = normalize_date_time(\n",
    "                AnomalyInputData[\"AnomalyEnd\"]\n",
    "            )\n",
    "\n",
    "    # validate anomaly dates\n",
    "\n",
    "    for i in range(len(AnomalyInputData)):\n",
    "        startDate = AnomalyInputData[\"AnomalyStart\"][i]\n",
    "        endDate = AnomalyInputData[\"AnomalyEnd\"][i]\n",
    "\n",
    "        # Anomaly Start Date must be after Investigation Start Date\n",
    "        if startDate:\n",
    "            startDate = normalize_date_time(startDate)\n",
    "            if startDate.tzinfo != startDateInput.tzinfo:\n",
    "                raise MissingInputError(\"Anomaly Must Have End Date\")\n",
    "\n",
    "            if startDateInput > startDate:\n",
    "                raise WrongInputDataError(\n",
    "                    \"Anomaly Start Date must be after Investigation Start Date\"\n",
    "                )\n",
    "\n",
    "        else:\n",
    "            raise MissingInputError(\"Anomaly Must Have Start Date\")\n",
    "\n",
    "        # Anomaly End Date must be Before Investigation End Date\n",
    "        if endDate:\n",
    "            endDate = normalize_date_time(endDate)\n",
    "\n",
    "            if endDate.tzinfo != endDateInput.tzinfo:\n",
    "                raise MissingInputError(\"Anomaly Must Have End Date\")\n",
    "\n",
    "            if endDateInput < endDate:\n",
    "                raise WrongInputDataError(\n",
    "                    \"Anomaly End Date must be Before Investigation End Date\"\n",
    "                )\n",
    "\n",
    "        else:\n",
    "            raise MissingInputError(\"Anomaly Must Have Start Date\")\n",
    "\n",
    "        # check Anomaly Start Date Must Be Before End Date'\n",
    "        if startDate > endDate:\n",
    "            raise WrongInputDataError(\"Anomaly Start Date Must Be Before End Date\")\n",
    "\n",
    "        # add start and end anomalies to dictionary\n",
    "        knownAnomalies[\"startDate\"] = knownAnomalies.get(\"startDate\", []) + [startDate]\n",
    "        knownAnomalies[\"endDate\"] = knownAnomalies.get(\"endDate\", []) + [endDate]\n",
    "\n",
    "    return knownAnomalies\n",
    "\n",
    "\n",
    "def get_seeq_data(tagsToSearch, dataSource):\n",
    "    #     Purpose: Get meta data from seeq for given set of signals\n",
    "    #     Parameters: tagsToSearch: List: pi tag names to find seeq meta data for\n",
    "    #                 dataSource: List: pi datasource pi tag is in\n",
    "    #     Returns: Pandas Dataframe of seeq meta data\n",
    "    spySearchedItems = pd.DataFrame()\n",
    "\n",
    "    my_items = pd.DataFrame(\n",
    "        {\"Name\": tagsToSearch, \"Datasource Name\": dataSource, \"Type\": \"Signal\"}\n",
    "    )\n",
    "    with progressOutput:\n",
    "        spySearchedItems = spy.search(my_items)\n",
    "    progressOutput.clear_output()\n",
    "\n",
    "    if spySearchedItems.empty:\n",
    "        raise SeeqSpyError(\n",
    "            f\"Could Not Find PiTag: {tagsToSearch[0]}. CHECK SITE IS CORRECT\"\n",
    "        )\n",
    "\n",
    "    return spySearchedItems\n",
    "\n",
    "\n",
    "def get_manual_input_load_qgrid():\n",
    "    TestVariatonsDf = pd.DataFrame()\n",
    "    currTestDf = pd.DataFrame()\n",
    "    userInputManualFlag = True\n",
    "\n",
    "    # Reformat/shorten TestToRun_STB lists spy.push cannot handle long name (this is the name that will get pushed to WB)\n",
    "    TestToRun_LstTest = [x.split(\":\", 1)[0] for x in TestToRun_STB.value]\n",
    "    # Get Test variations based on onscreen inputs\n",
    "    TestVariatons = format_test_Variations(TestToRun_LstTest, userInputManualFlag, \"\")\n",
    "\n",
    "    # message for greater than 10 signals\n",
    "    if TestVariatonsDf.shape[0] > 10:\n",
    "        pop_up(\"WARNING more than 10 models per signal will slow down SEEQ worksbooks.\")\n",
    "\n",
    "    # Build Tests, for each test selected add test variations\n",
    "    numOfVariations = len(TestToRun_LstTest)\n",
    "    for i in range(numOfVariations):\n",
    "        currTestDf = pd.DataFrame(TestVariatons)\n",
    "        currTestDf.insert(0, \"TestName\", TestToRun_LstTest[i])\n",
    "\n",
    "        TestVariatonsDf = pd.concat([TestVariatonsDf, currTestDf], axis=0)\n",
    "\n",
    "    # put Test variations in data frame and format index column to be shown in Qgrid\n",
    "    TestVariatonsDf.reset_index(drop=True, inplace=True)\n",
    "    TestVariatonsDf.index += 1\n",
    "    TestVariatonsDf.reset_index(inplace=True)\n",
    "    TestVariatonsDf = TestVariatonsDf.rename(columns={\"index\": \"Model\"})\n",
    "\n",
    "    TestVariatonsDf\n",
    "\n",
    "    # get QGrid for test variations\n",
    "    TestVariatonsQgrid = load_ManualData_qgrid(TestVariatonsDf)\n",
    "    # load Qgrid to screen\n",
    "    lst = list(QgridManualTbleWidget.children[0].children)\n",
    "    lst[0] = TestVariatonsQgrid\n",
    "    QgridManualTbleWidget.children[0].children = lst\n",
    "    QgridManualTbleWidget.layout.visibility = \"visible\"\n",
    "\n",
    "\n",
    "def load_ManualData_qgrid(ManualUserData):\n",
    "    #     Purpose: setting perameters adn build Qgrid for widgets to use\n",
    "    #     Parameters: ManualUserData: DataFrame: Data to be put in qgrid\n",
    "    #     Returns: Qgrid table\n",
    "    global qgridUpload\n",
    "\n",
    "    gridOps = {\n",
    "        # SlickGrid options\n",
    "        \"fullWidthRows\": False,\n",
    "        \"syncColumnCellResize\": True,\n",
    "        \"forceFitColumns\": False,\n",
    "        #'defaultColumnWidth': 150,\n",
    "        \"rowHeight\": 25,\n",
    "        \"enableColumnReorder\": True,\n",
    "        \"enableTextSelectionOnCells\": True,\n",
    "        \"editable\": False,\n",
    "        \"autoEdit\": False,\n",
    "        \"explicitInitialization\": True,\n",
    "        # Qgrid options\n",
    "        \"maxVisibleRows\": 5,\n",
    "        \"minVisibleRows\": 5,\n",
    "        \"sortable\": True,\n",
    "        \"filterable\": True,\n",
    "        \"highlightSelectedCell\": True,\n",
    "        \"highlightSelectedRow\": True,\n",
    "        \"resizable\": True,\n",
    "    }\n",
    "\n",
    "    qgridUpload = qgrid.show_grid(\n",
    "        ManualUserData,\n",
    "        show_toolbar=False,\n",
    "        grid_options=gridOps,\n",
    "        column_definitions={\n",
    "            \"index\": {\"maxWidth\": 0, \"minWidth\": 0, \"width\": 0},\n",
    "            \"Model\": {\"maxWidth\": None, \"minWidth\": None, \"width\": 30},\n",
    "        },\n",
    "    )\n",
    "    return qgridUpload\n",
    "\n",
    "\n",
    "def load_bulkData_qgrid(bulkUploadUserData):\n",
    "    #     Purpose: setting perameters adn build Qgrid for widgets to use\n",
    "    #     Parameters: bulkUploadUserData: DataFrame: Data to be put in qgrid\n",
    "    #     Returns: Qgrid table\n",
    "    global qgridUpload\n",
    "\n",
    "    gridOps = {\n",
    "        # SlickGrid options\n",
    "        \"fullWidthRows\": True,\n",
    "        \"syncColumnCellResize\": True,\n",
    "        \"forceFitColumns\": False,\n",
    "        #'defaultColumnWidth': 150,\n",
    "        \"rowHeight\": 25,\n",
    "        \"enableColumnReorder\": True,\n",
    "        \"enableTextSelectionOnCells\": True,\n",
    "        \"editable\": True,\n",
    "        \"autoEdit\": False,\n",
    "        \"explicitInitialization\": True,\n",
    "        # Qgrid options\n",
    "        \"maxVisibleRows\": 10,\n",
    "        \"minVisibleRows\": 10,\n",
    "        \"sortable\": True,\n",
    "        \"filterable\": True,\n",
    "        \"highlightSelectedCell\": True,\n",
    "        \"highlightSelectedRow\": True,\n",
    "        \"resizable\": True,\n",
    "    }\n",
    "\n",
    "    qgridUpload = qgrid.show_grid(\n",
    "        bulkUploadUserData,\n",
    "        show_toolbar=True,\n",
    "        grid_options=gridOps,\n",
    "        column_definitions={\n",
    "            \"index\": {\"maxWidth\": 0, \"minWidth\": 0, \"width\": 0},\n",
    "            \"Name\": {\"maxWidth\": None, \"minWidth\": None, \"width\": 280},\n",
    "        },\n",
    "    )\n",
    "    return qgridUpload\n",
    "\n",
    "\n",
    "def load_Anomaly_qgrid(AnomalyData):\n",
    "    #     Purpose: setting perameters adn build Qgrid for widgets to use\n",
    "    #     Parameters: AnomalyData: DataFrame: Data to be put in qgrid\n",
    "    #     Returns: Qgrid table\n",
    "    global qgridAnomaly\n",
    "\n",
    "    gridOps = {\n",
    "        # SlickGrid options\n",
    "        \"fullWidthRows\": True,\n",
    "        \"syncColumnCellResize\": True,\n",
    "        \"forceFitColumns\": False,\n",
    "        #'defaultColumnWidth': 150,\n",
    "        \"rowHeight\": 25,\n",
    "        \"enableColumnReorder\": True,\n",
    "        \"enableTextSelectionOnCells\": False,\n",
    "        \"editable\": True,\n",
    "        \"autoEdit\": False,\n",
    "        \"explicitInitialization\": True,\n",
    "        # Qgrid options\n",
    "        \"maxVisibleRows\": 10,\n",
    "        \"minVisibleRows\": 10,\n",
    "        \"sortable\": True,\n",
    "        \"filterable\": True,\n",
    "        \"highlightSelectedCell\": True,\n",
    "        \"highlightSelectedRow\": True,\n",
    "        \"resizable\": True,\n",
    "    }\n",
    "\n",
    "    columnOps = {\n",
    "        # SlickGrid column options\n",
    "        \"defaultSortAsc\": True,\n",
    "        \"maxWidth\": None,\n",
    "        \"minWidth\": 30,\n",
    "        \"resizable\": True,\n",
    "        \"sortable\": True,\n",
    "        \"toolTip\": \"\",\n",
    "        \"width\": None,\n",
    "        # Qgrid column options\n",
    "        \"editable\": True,\n",
    "    }\n",
    "\n",
    "    qgridAnomaly = qgrid.show_grid(\n",
    "        AnomalyData,\n",
    "        show_toolbar=True,\n",
    "        grid_options=gridOps,\n",
    "        column_options=columnOps,\n",
    "        column_definitions={\"index\": {\"maxWidth\": 0, \"minWidth\": 0, \"width\": 0}},\n",
    "    )\n",
    "    return qgridAnomaly\n",
    "\n",
    "\n",
    "def pop_up(text):\n",
    "    #     Purpose: shows error message\n",
    "    #     Parameters: text for message to display\n",
    "    #     Returns: none\n",
    "    progressBar.layout.visibility = \"hidden\"\n",
    "    errorMessWidget.children[0].description = text\n",
    "    errorMessWidget.layout.visibility = \"visible\"\n",
    "    loading_overlay(False)\n",
    "\n",
    "\n",
    "def loading_overlay(disable):\n",
    "    #     Purpose: dissable or enable all screen inputs during loading. to prevent user form clicking buttons\n",
    "    #     Parameters: disable: Bool, true to dissable all screen inputs, False to enable all screen inputs\n",
    "    #     Returns: N/A\n",
    "    length = len(manualGrid.children)\n",
    "    for q in range(length):\n",
    "        manualGrid.children[q].disabled = disable\n",
    "\n",
    "\n",
    "def normalize_date_time(dateTimeToNorm):\n",
    "    #     Purpose: Convert or add input date and time to UTC time zone\n",
    "    #     Parameters: dateTimeToNorm: Date or DateTime: value to convert or add timezone to\n",
    "    #     Returns: dateTimeToNormCopy: DateTime: UTC formated date\n",
    "    #     try:\n",
    "    TzToUse = pytz.timezone(\"UTC\")\n",
    "    # check if dates to normalize are in a pandas series or single value\n",
    "    if isinstance(dateTimeToNorm, pd.Series):\n",
    "        if any(pd.isnull(dateTimeToNorm)):\n",
    "            raise NormalizeDateError(\"Error with normalizing Dates: null Date\")\n",
    "        #                 pop_up('Error with normalizing Dates: null Date')\n",
    "        #                 return ''\n",
    "        # get mask of rows with no time zones applied and timezones applied.\n",
    "        dateTimeToNormCopy = dateTimeToNorm.copy()\n",
    "        haszoneMask = dateTimeToNormCopy.apply(lambda t: t.tzinfo is not None)\n",
    "        nozoneMask = dateTimeToNormCopy.apply(lambda t: t.tzinfo is None)\n",
    "\n",
    "        # if Time zone already exits must convert timezone if no timezone currently exits must add time zone\n",
    "        if any(dateTimeToNormCopy[haszoneMask]):  # update time zones\n",
    "            dateTimeToNormCopy[haszoneMask] = pd.to_datetime(\n",
    "                dateTimeToNormCopy[haszoneMask]\n",
    "            ).dt.tz_convert(TzToUse)\n",
    "        if any(dateTimeToNormCopy[nozoneMask]):  # add Time zones\n",
    "            # NOTE: if no timezone exists we assume input was set as us/central zone then convert to UTC\n",
    "            dateTimeToNormCopy[nozoneMask] = pd.to_datetime(\n",
    "                dateTimeToNormCopy[nozoneMask]\n",
    "            ).dt.tz_localize(\"US/Central\")\n",
    "            dateTimeToNormCopy[nozoneMask] = pd.to_datetime(\n",
    "                dateTimeToNormCopy[nozoneMask]\n",
    "            ).dt.tz_convert(TzToUse)\n",
    "\n",
    "    else:\n",
    "        # single value to update or add timezone\n",
    "        dateTimeToNormCopy = dateTimeToNorm\n",
    "        dateTimeToNormCopy = pd.to_datetime(dateTimeToNormCopy)\n",
    "        # if time zone is none assume input was set as us/central zone then convert to UTC\n",
    "        if dateTimeToNormCopy.tzinfo == None:\n",
    "            dateTimeToNormCopy = dateTimeToNormCopy.tz_localize(\"US/Central\")\n",
    "\n",
    "        dateTimeToNormCopy = dateTimeToNormCopy.tz_convert(TzToUse)\n",
    "\n",
    "    return dateTimeToNormCopy\n",
    "\n",
    "\n",
    "def report_date_time(dateTimeToReport):\n",
    "    #     Purpose: Convert normalized date time to us/central. if passed in datetime does not have timezone will normalize before converting\n",
    "    #     Parameters: dateTimeToReport: Datetime: with or without time zone\n",
    "    #     Returns: dateTimeToReport: DateTime: US/Central formated date\n",
    "    #     try:\n",
    "    TzToUse = pytz.timezone(\"US/Central\")\n",
    "    # if time zone is none\n",
    "    if dateTimeToNorm.tzinfo == None:\n",
    "        dateTimeToReport = normalize_date_time(dateTimeToReport)\n",
    "\n",
    "    dateTimeToReport.tz_convert(\"US/Central\")\n",
    "\n",
    "    return dateTimeToReport\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9ebff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc6064f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EquipmentSignals:\n",
    "    #     Purpose: Provide required functions to format and get SPY data for a give set of PI Tags on Equipment for\n",
    "    #              models/testing methods to be created\n",
    "    #     Pre-Conditions: A Pandas DataFrame of PI Tags and settings must be set\n",
    "    #     Post-Conditions: ModelingTechniques class will be used with other functions to build and output results\n",
    "    #     Parameters: rawPiTagsDF: Dataframe with the following columns:\n",
    "    #                                 investigationDate: Date analisis is based on\n",
    "    #                                 , StartDate: date to start, EndDate\n",
    "    #                                 , piTag, site, runStatusTag, runStatusCondition,\n",
    "    #                                 testMethods, historian, anomalyDate,\n",
    "    #                                 anomalyBehavior, testVariations\n",
    "    #     Returns:N/A\n",
    "    def __init__(self, rawPiTagsDF):\n",
    "        self.SignalDB = pd.DataFrame()\n",
    "        runStatusSignalDb = pd.DataFrame()\n",
    "        mainSigDb = pd.DataFrame()\n",
    "\n",
    "        # Get DataFrame for main model tags seeq search\n",
    "        mainSigDb = self.get_main_signal(rawPiTagsDF)\n",
    "\n",
    "        if not mainSigDb.empty:\n",
    "            # Add test methods and test variations to models database\n",
    "            mainSigDb = pd.merge(\n",
    "                mainSigDb,\n",
    "                rawPiTagsDF[\n",
    "                    [\n",
    "                        \"piTag\",\n",
    "                        \"testMethods\",\n",
    "                        \"testVariations\",\n",
    "                        \"startDate\",\n",
    "                        \"endDate\",\n",
    "                        \"knownAnomalies\",\n",
    "                    ]\n",
    "                ],\n",
    "                left_on=\"Name\",\n",
    "                right_on=\"piTag\",\n",
    "                how=\"left\",\n",
    "            )\n",
    "\n",
    "            progressBar.value = 3\n",
    "\n",
    "            # get runstatus signals tags seeq search\n",
    "            runStatusSignalDb = self.get_runstatus(rawPiTagsDF)\n",
    "\n",
    "            # Combine mainSigDb and runStatusSignalDb into one dataframe object\n",
    "            self.SignalDB = pd.merge(\n",
    "                mainSigDb,\n",
    "                runStatusSignalDb[list(runStatusSignalDb.columns.values)],\n",
    "                left_on=\"Name\",\n",
    "                right_on=\"mainSigpPTag_RS\",\n",
    "                how=\"inner\",\n",
    "            ).drop(\"mainSigpPTag_RS\", axis=1)\n",
    "\n",
    "    def get_main_signal(self, rawPiTagsDF):\n",
    "\n",
    "        mainSigDb = pd.DataFrame()\n",
    "        # seeq Search for tags\n",
    "        mainSigDb = self.get_equipment_data(rawPiTagsDF, \"piTag\")\n",
    "\n",
    "        # validate values are returned\n",
    "        if mainSigDb.empty:\n",
    "            raise SeeqSpyError(f\"Could Not MAIN SIGNAL PITAG: CHECK SITE IS CORRECT\")\n",
    "\n",
    "        # check to make sure all RunStatus were found by seeq search, if not error:\n",
    "        foundAllBool, errorMsg = self.validate_all_tags_found(\n",
    "            rawPiTagsDF, mainSigDb, \"piTag\", \"Name\"\n",
    "        )\n",
    "        if not foundAllBool:\n",
    "            raise SeeqSpyError(f\"Could Not MAIN SIGNAL PITAG: {errorMsg}\")\n",
    "        #             pop_up(errorMsg)\n",
    "        #             return mainSigDb\n",
    "\n",
    "        return mainSigDb\n",
    "\n",
    "    def get_runstatus(self, rawPiTagsDF):\n",
    "        runStatusSignalDb = pd.DataFrame()\n",
    "\n",
    "        # get rows that have need to have seeq search for run status\n",
    "        rsNeedsSeeqmask = rawPiTagsDF[\"runStatusTag\"].values != \"1\"\n",
    "        piTagNeedRSdf = rawPiTagsDF[rsNeedsSeeqmask].copy()\n",
    "\n",
    "        # create DataFrame for run status tags manually or by seeq search then combine all into one DF\n",
    "        if not piTagNeedRSdf.empty:\n",
    "            runStatusSignalDb = self.get_equipment_data(piTagNeedRSdf, \"runStatusTag\")\n",
    "            if runStatusSignalDb.empty:\n",
    "                raise SeeqSpyError(f\"Could Not FIND RUNSTATUS SIGNAL PITAG: {errorMsg}\")\n",
    "            #                 pop_up('Error finding runstatus pi tag')\n",
    "            #                 return runStatusSignalDb\n",
    "\n",
    "            # check to make sure all RunStatus were found by seeq search, if not error:\n",
    "            foundAllBool, errorMsg = self.validate_all_tags_found(\n",
    "                piTagNeedRSdf, runStatusSignalDb, \"runStatusTag\", \"Name\"\n",
    "            )\n",
    "            if not foundAllBool:\n",
    "                pop_up(errorMsg)\n",
    "                return runStatusSignalDb\n",
    "\n",
    "        else:\n",
    "            # create runstatus dataframe\n",
    "            runStatusSignalDb = pd.DataFrame(columns=[\"ID\", \"Name\"])\n",
    "\n",
    "        # add any run status that did not need seeq search: to make one DF of run status\n",
    "        # note adding 1.toSignal to ID, this will be put in the run status perameter for seeq formula\n",
    "        if not rawPiTagsDF[~rsNeedsSeeqmask].empty:\n",
    "            rsNameToAddLst = [\"1\"] * rawPiTagsDF[~rsNeedsSeeqmask].shape[0]\n",
    "            #             rsIDToAddLst = [x + '.toSignal()' for x in rsNameToAddLst]\n",
    "            #             rsToAddDF = pd.DataFrame({'ID': rsIDToAddLst, 'Name': rsNameToAddLst})\n",
    "            rsToAddDF = pd.DataFrame({\"Name\": rsNameToAddLst})\n",
    "            runStatusSignalDb = pd.concat(\n",
    "                [runStatusSignalDb, rsToAddDF], axis=0\n",
    "            ).reset_index(drop=True)\n",
    "\n",
    "        # Add Run status condition to Runstatus database and main signal pi tag to keep a key value of where run status belongs\n",
    "        runStatusSignalDb = pd.merge(\n",
    "            runStatusSignalDb,\n",
    "            rawPiTagsDF[[\"runStatusTag\", \"runStatusCondition\", \"piTag\"]],\n",
    "            left_on=\"Name\",\n",
    "            right_on=\"runStatusTag\",\n",
    "            how=\"left\",\n",
    "        ).rename(columns={\"piTag\": \"mainSigpPTag\"})\n",
    "\n",
    "        # add _RS to identify run status signals vs non runstatus signals\n",
    "        runStatusSignalDb.columns = [\n",
    "            str(col) + \"_RS\" for col in runStatusSignalDb.columns\n",
    "        ]\n",
    "\n",
    "        return runStatusSignalDb\n",
    "\n",
    "    def validate_all_tags_found(self, dfOrig, dfNew, leftOn, rightOn):\n",
    "        errorMsg = \"\"\n",
    "\n",
    "        # check to make sure all RunStatus were found by seeq search, if not error:\n",
    "        df_all = dfOrig.merge(\n",
    "            dfNew.drop_duplicates(),\n",
    "            left_on=leftOn,\n",
    "            right_on=rightOn,\n",
    "            how=\"left\",\n",
    "            indicator=True,\n",
    "        )\n",
    "        notFound = dfOrig[df_all[\"_merge\"] == \"left_only\"]\n",
    "        if not notFound.empty:\n",
    "            missingLst = list(notFound[leftOn])\n",
    "            errorMsg = f\"ERROR: Could Not find the Followng Run Status: {missingLst}\"\n",
    "            return False, errorMsg\n",
    "\n",
    "            #             df_all = piTagNeedRSdf.merge(runStatusSignalDb.drop_duplicates(), left_on='runStatusTag', right_on='Name',\n",
    "        #                                how='left', indicator=True)\n",
    "        #             notFoundRS = piTagNeedRSdf[df_all['_merge'] == 'left_only']\n",
    "        #             if not notFoundRS.empty:\n",
    "        #                 rsMissingLis =list(notFoundRS['runStatusTag'])\n",
    "        #                 pop_up(f'ERROR: Could Not find the Followng Run Status: {rsMissingLis}')\n",
    "        #                 return ''\n",
    "\n",
    "        return True, errorMsg\n",
    "\n",
    "    def get_equipment_data(self, rawPiTagsDF, reffTag):\n",
    "        #     Purpose: Provide required functions to format and get SPY data for a give set of PI Tags/ Equipment for model test\n",
    "        #              to be performed on\n",
    "        #     Pre-Conditions: A Pandas DataFrame of PI Tags and settings must be set\n",
    "        #     Post-Conditions: ModelingTechniques class will be used with other functions to build and output results\n",
    "        #     Parameters: rawPiTagsDF: Dataframe with the following columns:\n",
    "        #                             reffTag: tag to tell function if for runs status\n",
    "        #     Returns: tempmodelsData: spy. search result of piTags\n",
    "\n",
    "        tempmodelsData = pd.DataFrame()\n",
    "\n",
    "        # get unique values of all historians that the tags used. loop through each for spy.pull\n",
    "        historianDict = dict(enumerate(rawPiTagsDF.historian.unique()))\n",
    "\n",
    "        # loop through all historians doing spy.search data for all pi tags in that historian group\n",
    "        for db in historianDict:\n",
    "            thisHistorian = list(\n",
    "                rawPiTagsDF.loc[rawPiTagsDF[\"historian\"] == historianDict[db]]\n",
    "                .filter([reffTag])[reffTag]\n",
    "                .unique()\n",
    "            )\n",
    "            currentmodels = get_seeq_data(thisHistorian, historianDict[db])\n",
    "\n",
    "            # combine each spy.search for each historian\n",
    "            tempmodelsData = pd.concat([tempmodelsData, currentmodels], axis=0)\n",
    "\n",
    "        return tempmodelsData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab50963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968ec657",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelingTechnique:\n",
    "    #     Purpose: Provide required functions to create and deploy different Modeling Techniques on a given set of PI Tags\n",
    "    #              A Pandas DataFrame of PI Tags and settings must be set\n",
    "    #              ModelingTechniques class will be used with other functions to build and output results\n",
    "    #     Parameters:\n",
    "    #     Returns: none\n",
    "    def __init__(self, workbookFldr, equipmentData):\n",
    "        self.pushedResults = pd.DataFrame()\n",
    "        self.PushedResultsOrginalList = []\n",
    "\n",
    "        self.pushedResults = self.create_all_tests(equipmentData, workbookFldr)\n",
    "\n",
    "    def create_all_tests(self, equipmentData, workbookFldr):\n",
    "        #     Purpose: Provide required functionality to create a signal for spy.push\n",
    "        #             loop through each model and add desired tests to worksheet. each row is a worksheet\n",
    "        #             each worksheet is a set of models to test for single piTag.(w/ different variations ex window size ect.)\n",
    "        #     Parameters: equipmentData: DataFrame from EquipmentSignals() Class\n",
    "        #     Returns: allPushedResults: Pandas DF: compined DF of all pushed results from Seeq\n",
    "        allPushedResults = pd.DataFrame()\n",
    "        updateSeeqSigLimit = False\n",
    "        equipmentData = equipmentData.rename(\n",
    "            columns={\"Datasource Name\": \"DatasourceName\"}\n",
    "        )\n",
    "\n",
    "        # for each PiTag/equipment (IE.Row) in dataframe (note if in manual upload there will be only 1 row/piTag)\n",
    "        for row in equipmentData.itertuples():\n",
    "            mainSigType = \"Signal\"\n",
    "            mainSigFormula = \"$mainSignal\"\n",
    "            mainSigFormulaPara = f\"$mainSignal={row.ID}\"\n",
    "            sigName = row.Name\n",
    "            pushedResultsForRow = pd.DataFrame()\n",
    "            numOfTest = len(row.testMethods)\n",
    "\n",
    "            # for each TEST on current piTag/equipment(ie.Row) \"create\" and push TEST to WB. Each variation of\n",
    "           \n",
    "            for iTest in range(numOfTest):\n",
    "                formulaStr = \"\"\n",
    "                formulaStr1 = \"\"\n",
    "                formulaStr2 = \"\"\n",
    "                formulaPara = \"\"\n",
    "                formulaPara1 = \"\"\n",
    "                formulaPara2 = \"\"\n",
    "                testType = \"\"\n",
    "                sigType = \"\"\n",
    "                numOfVariations = len(row.testVariations[\"Wfdsgze\"])\n",
    "\n",
    "                # if there are more than 5 variations (ie. 10 signals) need to change update seeq signal limit\n",
    "                if numOfVariations > 5:\n",
    "                    updateSeeqSigLimit = True\n",
    "\n",
    "                # Two kinds of test: condition directly to signal given by user or create new signal and put condition on it\n",
    "                if (\n",
    "                    row.testMethods[iTest] == \"fsgasfore\"\n",
    "                    or row.testMethods[iTest] == \"DFit\"\n",
    "                ):\n",
    "                    # Put condition directly on PiTag from user\n",
    "                    TestSignalID = [row.ID] * numOfVariations\n",
    "\n",
    "                    # Z-SCORE\n",
    "                    if row.testMethods[iTest] == \"sadfcore\":\n",
    "                        formulaStr, formulaPara = self.create_z_score(\n",
    "                            row.testVariations,\n",
    "                            TestSignalID,\n",
    "                            row.ID_RS,\n",
    "                            row.runStatusCondition_RS,\n",
    "                        )\n",
    "\n",
    "                    # FIXED LIMIT\n",
    "                    if row.testMethods[iTest] == \"Fiqwert\"\n",
    "                        formulaStr, formulaPara = self.create_fixed_Limit(\n",
    "                            row.testVariations,\n",
    "                            TestSignalID,\n",
    "                            row.ID_RS,\n",
    "                            row.runStatusCondition_RS,\n",
    "                        )\n",
    "\n",
    "                    # Sig Type for spy.push, testType: this will be part of the name shown in the Work Book\n",
    "                    sigType = [\"Condition\"] * numOfVariations\n",
    "                    testType = [f\"{row.testMethods[iTest]}\"] * numOfVariations\n",
    "\n",
    "                else:\n",
    "                    # create signal for condition to be put on\n",
    "                    # OUT OF BOUNDS DISCRETE\n",
    "                    if (\n",
    "                        row.testMethods[iTest] == \"OusdghScore\"\n",
    "                        or row.testMethods[iTest]\n",
    "                        == \"Outdshmit\"\n",
    "                    ):\n",
    "                        # Get signals to be pushed to workbook\n",
    "                        formulaStr1, formulaPara1 = self.create_OutOfBounds_Descrete(\n",
    "                            row.testVariations,\n",
    "                            row.ID,\n",
    "                            row.ID_RS,\n",
    "                            row.runStatusCondition_RS,\n",
    "                        )\n",
    "                    # OUT OF BOUNDS CONTINUOUS\n",
    "                    if (\n",
    "                        row.testMethods[iTest] == \"Ouasdf-Score\"\n",
    "                        or row.testMethods[iTest]\n",
    "                        == \"Oudshit\"\n",
    "                    ):\n",
    "                        formulaStr1, formulaPara1 = self.create_OutOfBounds_Continuous(\n",
    "                            row.testVariations,\n",
    "                            row.ID,\n",
    "                            row.ID_RS,\n",
    "                            row.runStatusCondition_RS,\n",
    "                        )\n",
    "                    # FORCAST LIMIT\n",
    "                    if (\n",
    "                        row.testMethods[iTest] == \"Forecasasdfre\"\n",
    "                        or row.testMethods[iTest] == \"Foresdartytit\"\n",
    "                    ):\n",
    "                        formulaStr1, formulaPara1 = self.create_ForecastLimit(\n",
    "                            row.testVariations,\n",
    "                            row.ID,\n",
    "                            row.ID_RS,\n",
    "                            row.runStatusCondition_RS,\n",
    "                        )\n",
    "                    # FORCAST LIMIT FIXED WINDOW\n",
    "                    if (\n",
    "                        row.testMethods[iTest] == \"Foasdfore\"\n",
    "                        or row.testMethods[iTest]\n",
    "                        == \"Forecassdg\"\n",
    "                        (\n",
    "                            formulaStr1,\n",
    "                            formulaPara1,\n",
    "                        ) = self.create_ForecastLimit_FixedWindow(\n",
    "                            row.testVariations,\n",
    "                            row.ID,\n",
    "                            row.ID_RS,\n",
    "                            row.runStatusCondition_RS,\n",
    "                        )\n",
    "\n",
    "                    # Sig Type for spy.push, testType: this will be part of the name shown in the Work Book\n",
    "                    sigType1 = [\"Signal\"] * numOfVariations\n",
    "                    testType1 = [f\"{row.testMethods[iTest]}_Signal\"] * numOfVariations\n",
    "\n",
    "                    # Get Conditions to be pushed to Workbook\n",
    "                    # TestSignalID is name of new signal added that Zscore or Fixed Limit condition must be put on\n",
    "                    TestSignalID = [\n",
    "                        f\"{row.piTag}_{testType1[x]}_{x}\" for x in range(len(testType1))\n",
    "                    ]\n",
    "                    if \"z-score\" in row.testMethods[iTest].lower():\n",
    "                        formulaStr2, formulaPara2 = self.create_z_score(\n",
    "                            row.testVariations,\n",
    "                            TestSignalID,\n",
    "                            row.ID_RS,\n",
    "                            row.runStatusCondition_RS,\n",
    "                        )\n",
    "                    else:\n",
    "                        formulaStr2, formulaPara2 = self.create_fixed_Limit(\n",
    "                            row.testVariations,\n",
    "                            TestSignalID,\n",
    "                            row.ID_RS,\n",
    "                            row.runStatusCondition_RS,\n",
    "                        )\n",
    "\n",
    "                    sigType2 = [\"Condition\"] * numOfVariations\n",
    "                    testType2 = [\n",
    "                        f\"{row.testMethods[iTest]}_Condition\"\n",
    "                    ] * numOfVariations\n",
    "\n",
    "                    # Combine new Signal and Condition for that singal to be pushed to WB\n",
    "                    if any(formulaStr1) and any(formulaStr2):\n",
    "                        formulaStr = formulaStr1 + formulaStr2\n",
    "                    if any(formulaPara1) and any(formulaPara2):\n",
    "                        formulaPara = formulaPara1 + formulaPara2\n",
    "                    testType = testType1 + testType2\n",
    "                    sigType = sigType1 + sigType2\n",
    "\n",
    "                progressBar.value = 5\n",
    "                if any(formulaStr) and any(formulaPara):\n",
    "                    # push worksheet test/models to workbook\n",
    "                    pushedResults = self.push_test_signal(\n",
    "                        mainSigType,\n",
    "                        mainSigFormula,\n",
    "                        mainSigFormulaPara,\n",
    "                        sigName,\n",
    "                        sigType,\n",
    "                        formulaStr,\n",
    "                        formulaPara,\n",
    "                        testType,\n",
    "                        workbookFldr,\n",
    "                    )\n",
    "\n",
    "                    # Add orginal Signal Name to each row\n",
    "                    pushedResults[\"SignalName\"] = sigName\n",
    "                    # add all test/models variations to pushed results\n",
    "                    pushedResultsForRow = pd.concat(\n",
    "                        [pushedResultsForRow, pushedResults], axis=0\n",
    "                    )\n",
    "                else:\n",
    "                    raise WrongInputDataError(\n",
    "                        f\"No Tests Created, no formula string was able to be formulated for: {row.testMethods[iTest]}\"\n",
    "                    )\n",
    "        \n",
    "            # add all tests for row to DF\n",
    "            allPushedResults = pd.concat(\n",
    "                [allPushedResults, pushedResultsForRow], axis=0\n",
    "            )\n",
    "\n",
    "        # filter out main signals only want DF of tests/models\n",
    "        # only need the CalculatedConditions, and 'ID', 'Type', 'SignalName','Formula'\n",
    "        allPushedResults = allPushedResults.loc[\n",
    "            allPushedResults[\"Type\"] == \"CalculatedCondition\"\n",
    "        ]\n",
    "        allPushedResults = allPushedResults.loc[\n",
    "            :, [\"ID\", \"Type\", \"Name\", \"SignalName\", \"Formula\"]\n",
    "        ]\n",
    "        allPushedResults.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        progressBar.value = 6\n",
    "        # Check if Seeq WB needs to be updated to show more signals\n",
    "        if updateSeeqSigLimit:\n",
    "            self.increase_seeqwbsignal_limit(self.PushedResultsOrginalList)\n",
    "\n",
    "        return allPushedResults\n",
    "\n",
    "    def push_test_signal(\n",
    "        self,\n",
    "        mainSigType,\n",
    "        mainSigFormula,\n",
    "        mainSigFormulaPara,\n",
    "        sigName,\n",
    "        sigType,\n",
    "        formulaStr,\n",
    "        formulaPara,\n",
    "        testType,\n",
    "        workbookFldr,\n",
    "    ):\n",
    "        #     Purpose: Provide required functionality to push signals and modeling Techiques to a workbook\n",
    "      \n",
    "        PushedResults = pd.DataFrame()\n",
    "        thisModelMetaToPush = pd.DataFrame()\n",
    "        thisModelWorksheetName = f\"{sigName}_{testType[0]}\"\n",
    "\n",
    "        # Build dataframe for main signal test is on for spy.push to push to worksheet\n",
    "        mainSignal = pd.DataFrame(\n",
    "            {\n",
    "                \"Name\": sigName,\n",
    "                \"Type\": mainSigType,\n",
    "                \"Formula\": mainSigFormula,\n",
    "                \"Formula Parameters\": [mainSigFormulaPara],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Build DataFrame row for for each variation of modeling techinque test for spy.push to push to worksheet\n",
    "        testSignalAll = pd.DataFrame()\n",
    "        numberOfVariationStr = len(formulaStr)\n",
    "\n",
    "        for i in range(numberOfVariationStr):\n",
    "            testSignal = pd.DataFrame(\n",
    "                {\n",
    "                    \"Name\": f\"{sigName}_{testType[i]}_{i}\",\n",
    "                    \"Type\": sigType[i],\n",
    "                    \"Formula\": formulaStr[i],\n",
    "                    \"Formula Parameters\": [formulaPara[i]],\n",
    "                }\n",
    "            )\n",
    "\n",
    "            testSignalAll = pd.concat([testSignalAll, testSignal], axis=0)\n",
    "\n",
    "        # Combine main signal and each variation of tests for worksheet into one dataFrame\n",
    "        thisModelMetaToPush = pd.concat([mainSignal, testSignalAll], axis=0)\n",
    "        thisModelMetaToPush.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        with progressOutput:\n",
    "            # push worksheet to workbook\n",
    "            PushedResults = spy.push(\n",
    "                metadata=thisModelMetaToPush,\n",
    "                workbook=workbookFldr,\n",
    "                worksheet=thisModelWorksheetName,\n",
    "            )\n",
    "        progressOutput.clear_output()\n",
    "\n",
    "        if PushedResults.empty:\n",
    "            progressOutput.clear_output()\n",
    "            raise WrongInputDataError(\n",
    "                \"Models were not able to be pushed to Seeq Workbook. Please check that the run status value given is the same type as in Seeq\"\n",
    "            )\n",
    "\n",
    "        # when returning Dataframe the attributes from spy get lost so make this mastercopy to keep access to attributes\n",
    "        self.PushedResultsOrginalList.append(PushedResults)\n",
    "\n",
    "        return PushedResults\n",
    "\n",
    "    def increase_seeqwbsignal_limit(self, pushedResList):\n",
    "        #     Purpose: seeq has limi of 10 signals on a workbook, this function will make all signals shown\n",
    "        #     Parameters:pushedResList: pandas Dataframe of all signals and models pushed to seeq (spy.push output)\n",
    "        #     Returns: N/A\n",
    "        # pull all work sheets then loop through each and readd all signals in push results\n",
    "\n",
    "        with progressOutput:\n",
    "            wb = spy.workbooks.pull(pushedResList[0].spy.workbook_url)[0]\n",
    "            ws = wb.worksheets\n",
    "            for wsNum in range(len(ws)):\n",
    "                thisWs = wb.worksheets[wsNum]\n",
    "                thisWs.display_items = pushedResList[wsNum]\n",
    "            spy.workbooks.push(wb)\n",
    "\n",
    "        progressOutput.clear_output()\n",
    "\n",
    "    # **************functions to create FHR tests in seeq: Start**************\n",
    "    #removed....\n",
    "   \n",
    "\n",
    "\n",
    "# **************functions to create FHR tests in seeq: END**************\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7926b5e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d7c95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Capsules:\n",
    "    def __init__(self, dataforModels, pushedResults, anomalyCatchWindow):\n",
    "        #     Purpose: Provide required functions to find and put in data frame all capssules for a set of models in a time frame\n",
    "        #     Pre-Conditions: A Pandas DataFrame of pushed tests\n",
    "        #     Post-Conditions:\n",
    "        #     Parameters:\n",
    "        #     Returns: none\n",
    "        self.capsuleTable = pd.DataFrame()\n",
    "        self.capsuleCountTble = pd.DataFrame()\n",
    "        self.capsuleDurationTble = pd.DataFrame()\n",
    "        self.durationSummaryTable = pd.DataFrame()\n",
    "        self.confusionMatSummaryTable = pd.DataFrame()\n",
    "        self.anomalies = pd.DataFrame()\n",
    "        self.falseNegativeTable = pd.DataFrame()\n",
    "        self.finalSumTble = pd.DataFrame()\n",
    "        self.finalSumTble_Qgrid = qgrid.grid.QgridWidget\n",
    "\n",
    "        # get Capsules for all tests\n",
    "        startDate = dataforModels[\"startDate\"][0]\n",
    "        endDate = dataforModels[\"endDate\"][0]\n",
    "\n",
    "        self.capsuleTable = self.create_capsule_table(startDate, endDate, pushedResults)\n",
    "        progressBar.value = 8\n",
    "\n",
    "        # get metrics for capsules: count duration ect. Check if DF has values or if there is and string error\n",
    "        if any(self.capsuleTable) and type(self.capsuleTable) != str:\n",
    "            self.capsuleCountTble = self.create_count_table()\n",
    "\n",
    "            self.capsuleDurationTble = self.create_duration_table()\n",
    "\n",
    "            capsuleDurationTbleTest = self.capsuleDurationTble\n",
    "\n",
    "            self.durationSummaryTable = self.create_durationsummary_table(\n",
    "                self.capsuleDurationTble\n",
    "            )\n",
    "\n",
    "            # get anomalyies and if any exists (dictionary) label capsules and get Confusion Matrix summary(ie. True Positive etc.)\n",
    "            self.anomalies = dataforModels[[\"Name\", \"knownAnomalies\"]]\n",
    "\n",
    "            # check if any anomalies exist: anomalies are dictionaies in DataFrame\n",
    "            if len(Equipment.SignalDB[\"knownAnomalies\"].iloc[0]) > 0:\n",
    "\n",
    "                (\n",
    "                    self.capsuleTable,\n",
    "                    self.falseNegativeTable,\n",
    "                ) = self.create_Labled_capsule_table(\n",
    "                    self.anomalies, anomalyCatchWindow, self.capsuleTable, pushedResults\n",
    "                )\n",
    "\n",
    "                self.confusionMatSummaryTable = self.create_confusionMatSummary_table(\n",
    "                    self.capsuleTable, self.falseNegativeTable\n",
    "                )\n",
    "\n",
    "            # create Final Sumamry Table:\n",
    "            self.finalSumTble = self.create_FinalSum_capsule_table(\n",
    "                pushedResults,\n",
    "                self.capsuleCountTble,\n",
    "                self.durationSummaryTable,\n",
    "                self.confusionMatSummaryTable,\n",
    "            )\n",
    "\n",
    "            # format Final Summary table for QGrid\n",
    "            self.finalSumTble_Qgrid = self.create_QGrid_finalSumTble(self.finalSumTble)\n",
    "\n",
    "    def create_capsule_table(self, startDate, endDate, pushedResults):\n",
    "        #     Purpose: Provide required functions to pull data for signal and create DF of each capsuel for all tests\n",
    "        #             ModelingTechniques class created and signals have been pushed to workbook.\n",
    "        #     Parameters:\n",
    "        #     Returns: generatedCapsules\n",
    "        generatedCapsules = pd.DataFrame()\n",
    "\n",
    "        with progressOutput:\n",
    "            generatedCapsules = spy.pull(\n",
    "                pushedResults, start=startDate, end=endDate, grid=\"1hr\"\n",
    "            )\n",
    "        progressOutput.clear_output()\n",
    "\n",
    "        if any(generatedCapsules):\n",
    "            # Add ID and Name to DF to have ability to tie back to pushResults DF and orginal Data DF\n",
    "            generatedCapsules = pd.merge(\n",
    "                generatedCapsules,\n",
    "                pushedResults[[\"SignalName\", \"ID\", \"Name\"]],\n",
    "                left_on=\"Condition\",\n",
    "                right_on=\"Name\",\n",
    "                how=\"left\",\n",
    "            )\n",
    "\n",
    "            generatedCapsules = generatedCapsules.drop(\n",
    "                [\"Name\"], axis=1\n",
    "            )  # do not need Name column\n",
    "            generatedCapsules[\"confusionMatrix\"] = \"\"\n",
    "            generatedCapsules = generatedCapsules.sort_values(by=[\"Condition\"])\n",
    "            generatedCapsules.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            # Make sure both Date Times exist: (seeq Capsules will not have end or start if capsule is >or< investigationDate)\n",
    "            NullCapsStartDate = generatedCapsules[\n",
    "                pd.isnull(generatedCapsules[\"Capsule Start\"])\n",
    "            ]\n",
    "            NullCapsEndDate = generatedCapsules[\n",
    "                pd.isnull(generatedCapsules[\"Capsule End\"])\n",
    "            ]\n",
    "            if any(NullCapsStartDate):\n",
    "                generatedCapsules.loc[:, \"Capsule Start\"] = generatedCapsules[\n",
    "                    \"Capsule Start\"\n",
    "                ].fillna(userInputs[\"startDate\"][0])\n",
    "            if any(NullCapsEndDate):\n",
    "                generatedCapsules.loc[:, \"Capsule End\"] = generatedCapsules[\n",
    "                    \"Capsule End\"\n",
    "                ].fillna(userInputs[\"endDate\"][0])\n",
    "\n",
    "            # Make sure that dateTimes are normalized with same Time Zone:\n",
    "            normlizedStartDate = normalize_date_time(generatedCapsules[\"Capsule Start\"])\n",
    "            normlizedEndDate = normalize_date_time(generatedCapsules[\"Capsule End\"])\n",
    "            if any(normlizedStartDate) and any(normlizedEndDate):\n",
    "                generatedCapsules.loc[:, \"Capsule Start\"] = normlizedStartDate\n",
    "                generatedCapsules.loc[:, \"Capsule End\"] = normlizedEndDate\n",
    "            else:\n",
    "                return \"ERROR\"\n",
    "\n",
    "        return generatedCapsules\n",
    "\n",
    "    def create_count_table(self):\n",
    "        #     Purpose: Provide required functions to find and put in data frame all capssules for a set of models in a time frame\n",
    "        #     Pre-Conditions: Capsule class created and table of capsules had been created and has values.\n",
    "        #     Post-Conditions:\n",
    "        # \n",
    "        # get count of capsules for all test methods\n",
    "        count_caps = self.capsuleTable.groupby([\"Condition\"]).count().copy()\n",
    "\n",
    "        # copy count of capsule DF to new DF and move index to column (rename as \"name\") and give new index\n",
    "        # NOTE, use ID instead of Start or end Date, bc. some capaules start wont have start or end date\n",
    "        count_caps = count_caps.filter([\"ID\"], axis=1).rename(\n",
    "            columns={\"ID\": \"countCapsules\"}\n",
    "        )\n",
    "        count_caps.insert(loc=0, column=\"name\", value=count_caps.index)\n",
    "        count_caps.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        return count_caps\n",
    "\n",
    "    def create_duration_table(self):\n",
    "        #     Purpose: Provide required functions to duration for all capsules\n",
    "        #     Pre-Conditions: Capsule class created with table of capsules having values.\n",
    "\n",
    "        capDurTble = self.capsuleTable.copy()\n",
    "\n",
    "        # calculate duration\n",
    "        capDurTble[\"capsule_duration\"] = (\n",
    "            capDurTble[\"Capsule End\"] - capDurTble[\"Capsule Start\"]\n",
    "        )\n",
    "        capDurTble = capDurTble.filter(\n",
    "            [\"Condition\", \"ID\", \"Capsule Start\", \"capsule_duration\"], axis=1\n",
    "        ).rename(columns={\"Condition\": \"name\", \"Capsule Start\": \"capsuleStart\"})\n",
    "\n",
    "        return capDurTble\n",
    "\n",
    "    def create_confusionMatSummary_table(self, capTable, falseNegativeDF):\n",
    "        #         Purpose: Format results of labled capsules (ie. create_Labled_capsule_table()) for final sum table\n",
    "        #         Parameters: capTable: Pandas dataframe: of capsules returned by Seeq, Labled with true and false Positives\n",
    "        #                     falseNegativeDF: Pandas dataframe of false negatives\n",
    "        #         Returns: UpdatedConfusionMatSummary: Pandas data frame:of formated true positive, false positives and false negatives\n",
    "\n",
    "        confusionMatSummary = (\n",
    "            capTable.groupby([\"Condition\", \"confusionMatrix\"]).count().copy()\n",
    "        )\n",
    "        confusionMatSummary = confusionMatSummary.filter(\n",
    "            [\"Condition\", \"confusionMatrix\", \"ID\"], axis=1\n",
    "        ).rename(columns={\"ID\": \"countConfMat\"})\n",
    "\n",
    "        confusionMatSummary = confusionMatSummary.reset_index()\n",
    "        FalsePositiveTemp = confusionMatSummary.loc[\n",
    "            confusionMatSummary.confusionMatrix == \"FalsePositive\"\n",
    "        ]\n",
    "        TruePositiveTemp = confusionMatSummary.loc[\n",
    "            confusionMatSummary.confusionMatrix == \"TruePositive\"\n",
    "        ]\n",
    "\n",
    "        FalsePositiveTemp.reset_index(drop=True, inplace=True)\n",
    "        TruePositiveTemp.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        FalsePositiveTemp.loc[:, \"FalsePositive\"] = FalsePositiveTemp[\"countConfMat\"]\n",
    "        FalsePositiveTemp = FalsePositiveTemp.drop(\n",
    "            [\"confusionMatrix\", \"countConfMat\"], axis=1\n",
    "        )\n",
    "\n",
    "        TruePositiveTemp.loc[:, \"TruePositive\"] = TruePositiveTemp[\"countConfMat\"]\n",
    "        TruePositiveTemp = TruePositiveTemp.drop(\n",
    "            [\"confusionMatrix\", \"countConfMat\"], axis=1\n",
    "        )\n",
    "\n",
    "        UpdatedConfusionMatSummary = pd.merge(\n",
    "            TruePositiveTemp, FalsePositiveTemp, on=\"Condition\", how=\"outer\"\n",
    "        )\n",
    "\n",
    "        # add False Negatives\n",
    "        falseNegativeDFCopy = (\n",
    "            falseNegativeDF.groupby([\"Name\"])\n",
    "            .count()\n",
    "            .drop([\"Type\", \"SignalName\", \"AnomalyMissedDate\", \"Formula\"], axis=1)\n",
    "            .rename(columns={\"ID\": \"FalseNegatives\"})\n",
    "            .copy()\n",
    "        )\n",
    "\n",
    "        falseNegativeDFCopy[\"Condition\"] = falseNegativeDFCopy.index\n",
    "        falseNegativeDFCopy.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        UpdatedConfusionMatSummary = pd.merge(\n",
    "            UpdatedConfusionMatSummary,\n",
    "            falseNegativeDFCopy[[\"Condition\", \"FalseNegatives\"]],\n",
    "            on=\"Condition\",\n",
    "            how=\"outer\",\n",
    "        )\n",
    "\n",
    "        UpdatedConfusionMatSummary.fillna(0, inplace=True)\n",
    "\n",
    "        return UpdatedConfusionMatSummary\n",
    "\n",
    "    def create_durationsummary_table(self, capsuleDurationTble):\n",
    "        #     Purpose: format capsule druations to be viewd in final sum table\n",
    "        #     Parameters: capsuleDurationTble: pandas dataframe of summation of capsules\n",
    "        #     Returns: durationSummary: pandas dataframe of duration of capsules\n",
    "        durationSummary = pd.DataFrame()\n",
    "        durationSummary = (\n",
    "            capsuleDurationTble.groupby(\"name\")[[\"capsule_duration\"]].sum().copy()\n",
    "        )\n",
    "        durationSummary[\"name\"] = durationSummary.index\n",
    "        durationSummary.reset_index(drop=True, inplace=True)\n",
    "        # Condition\n",
    "        return durationSummary\n",
    "\n",
    "    def create_Labled_capsule_table(\n",
    "        self, anomalies, anomalyCatchWindow, capsuleTablePassed, pushedResults\n",
    "    ):\n",
    "        #     Purpose: find true positives, false posistives, and false negatives for a DF of capsules and anomaly dates\n",
    "        #             TRUE POSTIVE:for each pi tag / equipment go through each anomaly given and check to see if any capsules\n",
    "        #             exist in range(anomalyMatches DF) if capsule exist in anomaly range (anomalyMatches) record it as\n",
    "        #             TRUE POSITIVE in truePositiveDF and remove it from capsule DF.\n",
    "        #             FALSE NEGATIVES: each test variation/model is compared to anomalyMatches DF, if test is not\n",
    "        #             found in anomalyMatches add record of test to falseNegativeDF\n",
    "        #             FALSE POSITIVES: Once all anomalies have been gone through any capsule left in capsule copy\n",
    "        #             table labed as false positves in capsule table.\n",
    "        #             LASTLY: combine reindex and clean up false positive and true positive DF, and combine true postive and\n",
    "        #             false postive into one table (UpdatedCapsuleTable) and return UpdatedCapsuleTable and falseNegativeDF\n",
    "        #     Parameters: anomalies: Pandas dataframe of all anomalies with corresponding piTag given by user\n",
    "        #                     anomalyCatchWindow: pd.Timedelta: +- value in hours of what to consider an true positive for anomaly\n",
    "        #                     capsuleTablePassed: Pandas DataFrame of all capsules found: table return by Seeq.\n",
    "        #                     pushedResults: Pandas DataFrame of all pushed tests/models: table returnd by Seeq\n",
    "        #     Returns: UpdatedCapsuleTable: pandas dataframe of all capsules found by seeq with labels of true positve or false Positive\n",
    "        #                 falseNegativeDF: pandas dataframe: of all False Negatives\n",
    "\n",
    "        pushedResultsDF = pushedResults.copy()\n",
    "        captbleCopy = capsuleTablePassed.copy()\n",
    "        UpdatedCapsuleTable = pd.DataFrame()\n",
    "        truePositiveDF = pd.DataFrame()\n",
    "        falseNegativeDF = pd.DataFrame()\n",
    "        falseNegativeDF = pd.DataFrame(\n",
    "            columns=[\"ID\", \"Type\", \"Name\", \"SignalName\", \"Formula\", \"AnomalyMissedDate\"]\n",
    "        )\n",
    "\n",
    "        # make sure date times are normalized, all dates should be normalized when first brought into program.\n",
    "        captbleCopy.loc[:, \"Capsule Start\"] = normalize_date_time(\n",
    "            captbleCopy[\"Capsule Start\"].copy()\n",
    "        )\n",
    "        captbleCopy.loc[:, \"Capsule End\"] = normalize_date_time(\n",
    "            captbleCopy[\"Capsule End\"].copy()\n",
    "        )\n",
    "\n",
    "        # for each Equipment/PiTag that there is a list of anamoly for\n",
    "        for row in anomalies.itertuples():\n",
    "            # get anomalies for current row /pitag and check that any exist\n",
    "            anomDic = row.knownAnomalies\n",
    "            if len(anomDic) > 0:\n",
    "                # get all capsules for current Equipment/PiTag (ie row.name in anomalies)\n",
    "                currentCaps = pd.DataFrame()\n",
    "                currentCaps = captbleCopy[\n",
    "                    captbleCopy[\"SignalName\"].isin([row.Name])\n",
    "                ].copy()\n",
    "\n",
    "                # get a Copy of the tests for current Pi Tag (10AI118) and add anomaly missed column. Used for False negatives\n",
    "                currentPushedTests = pushedResultsDF.loc[\n",
    "                    pushedResultsDF[\"SignalName\"] == row.Name\n",
    "                ].copy()\n",
    "                currentPushedTests.loc[:, \"AnomalyMissedDate\"] = \"\"\n",
    "\n",
    "                # for each anamoly in list of anoamoly for this Equipment/PiTag:\n",
    "                numOfAnamoly = len(anomDic[\"startDate\"])\n",
    "                for i in range(numOfAnamoly):\n",
    "                    anomalyMatches = pd.DataFrame()\n",
    "                    # Get anomaly and capsule dates\n",
    "                    anomStartDate = anomDic[\"startDate\"][i]\n",
    "                    anomEndDate = anomDic[\"endDate\"][i]\n",
    "                    capStartDate = currentCaps[\"Capsule Start\"]\n",
    "                    capEndDate = currentCaps[\"Capsule End\"]\n",
    "\n",
    "                    # TRUE POSITIVES:\n",
    "                    # get all capsule that fall in anamoly range\n",
    "                    mask = (capStartDate >= (anomStartDate - anomalyCatchWindow)) & (\n",
    "                        capEndDate <= (anomEndDate + anomalyCatchWindow)\n",
    "                    ) | (capStartDate <= (anomStartDate - anomalyCatchWindow)) & (\n",
    "                        capEndDate >= (anomEndDate + anomalyCatchWindow)\n",
    "                    )\n",
    "                    anomalyMatches = currentCaps.loc[mask].copy()\n",
    "                    anomalyMatches.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                    # if there capsules that fall in anomaly range record them as true positive and remove from DF\n",
    "                    if not anomalyMatches.empty:\n",
    "                        # if found a capsule for anamoly then add it to truePositive DF\n",
    "                        truePositiveDF = pd.concat(\n",
    "                            [truePositiveDF, anomalyMatches], axis=0\n",
    "                        )\n",
    "                        # drop capsules (rows) that capsules match anomaly (IE. Catches) from capsule copy table\n",
    "                        captbleCopy = (\n",
    "                            pd.merge(\n",
    "                                captbleCopy, anomalyMatches, indicator=True, how=\"outer\"\n",
    "                            )\n",
    "                            .query('_merge==\"left_only\"')\n",
    "                            .drop(\"_merge\", axis=1)\n",
    "                        )\n",
    "                        captbleCopy.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                    # FALSE NEGATIVES:\n",
    "                    # check if any test variation /model for this Pitag/Equipment did Not Alert (ie has true positive)\n",
    "                    # for each test (10AI118.LC_Zscore_0) for current pi Tag (10AI118) in all pushed tests (Pused Results)\n",
    "                    numOftests = len(currentPushedTests[\"Name\"])\n",
    "                    for j in range(numOftests):\n",
    "                        if not currentPushedTests[\"Name\"].iloc[j] in list(\n",
    "                            anomalyMatches[\"Condition\"]\n",
    "                        ):\n",
    "                            # add missed alert to False running negative list\n",
    "                            currentPushedTests.loc[:, \"AnomalyMissedDate\"].iloc[j] = [\n",
    "                                anomStartDate\n",
    "                            ]\n",
    "                            falseNegativeDF = pd.concat(\n",
    "                                [falseNegativeDF, currentPushedTests.iloc[[j]]], axis=0\n",
    "                            )\n",
    "\n",
    "                # FALSE POSITIVES:\n",
    "                # Any capsule for pitag still in capsule copy DF means it did not fall in an anamoly range\n",
    "                # range. label capsule as false Positive: ie. should not have alerted\n",
    "                captbleCopy.loc[\n",
    "                    captbleCopy[\"SignalName\"] == row.Name, \"confusionMatrix\"\n",
    "                ] = \"FalsePositive\"\n",
    "\n",
    "        falseNegativeDF = falseNegativeDF.sort_values(by=[\"Name\"])\n",
    "        falseNegativeDF.reset_index(drop=True, inplace=True)\n",
    "        # if anomalyCatchWindow is wide enough to cover two anomalies it can be added more than once.\n",
    "        truePositiveDF.drop_duplicates()\n",
    "        truePositiveDF[\"confusionMatrix\"] = \"TruePositive\"\n",
    "\n",
    "        # update and return Labed Capsule Table\n",
    "        UpdatedCapsuleTable = pd.concat([truePositiveDF, captbleCopy], axis=0)\n",
    "        UpdatedCapsuleTable.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        return (UpdatedCapsuleTable, falseNegativeDF)\n",
    "\n",
    "    def create_FinalSum_capsule_table(\n",
    "        self,\n",
    "        pushedResults,\n",
    "        capsuleCountTble,\n",
    "        durationSummaryTble,\n",
    "        confusionMatSummaryTble,\n",
    "    ):\n",
    "        #     Purpose:\n",
    "        #     Parameters:\n",
    "        #     Returns: Data Frame with Following Columns: ID, Type: Name: SignalName,\n",
    "        #                 Formula, CountCapsules, Capsule_duration, FalsePositive, TruePositive\n",
    "        SummaryTble = pd.DataFrame()\n",
    "\n",
    "        SummaryTble = pushedResults.copy().drop([\"Type\", \"ID\"], axis=1)\n",
    "\n",
    "        # Get info from Capsule Count\n",
    "        if not capsuleCountTble.empty:\n",
    "            SummaryTble = pd.merge(\n",
    "                SummaryTble,\n",
    "                capsuleCountTble[[\"name\", \"countCapsules\"]],\n",
    "                left_on=\"Name\",\n",
    "                right_on=\"name\",\n",
    "                how=\"left\",\n",
    "            ).drop([\"name\"], axis=1)\n",
    "\n",
    "            SummaryTble.fillna(0, inplace=True)\n",
    "\n",
    "        # Get info from Capsule Durration\n",
    "        if not durationSummaryTble.empty:\n",
    "            SummaryTble = pd.merge(\n",
    "                SummaryTble,\n",
    "                durationSummaryTble[[\"name\", \"capsule_duration\"]],\n",
    "                left_on=\"Name\",\n",
    "                right_on=\"name\",\n",
    "                how=\"left\",\n",
    "            ).drop([\"name\"], axis=1)\n",
    "\n",
    "            SummaryTble.fillna(\n",
    "                pd.Timedelta(days=0, hours=0, minutes=0, seconds=0), inplace=True\n",
    "            )\n",
    "\n",
    "        # Get info from CnfusionMatrix\n",
    "        if not confusionMatSummaryTble.empty:\n",
    "            SummaryTble = pd.merge(\n",
    "                SummaryTble,\n",
    "                confusionMatSummaryTble[\n",
    "                    [\"Condition\", \"FalsePositive\", \"TruePositive\", \"FalseNegatives\"]\n",
    "                ],\n",
    "                left_on=\"Name\",\n",
    "                right_on=\"Condition\",\n",
    "                how=\"left\",\n",
    "            ).drop([\"Condition\"], axis=1)\n",
    "\n",
    "        return SummaryTble\n",
    "\n",
    "    def create_QGrid_finalSumTble(self, finalSumTble):\n",
    "        #     Purpose: create and set options for final sum qgrid table\n",
    "        #     Parameters: finalSumTble: pandas dataframe of final values to show user\n",
    "        #     Returns: qgrid_widget\n",
    "\n",
    "        # copy final table, change capsule Duration to hours (Qgrid Does not like timedelta64[ns]), Update column Names for readability\n",
    "        capsuleFinalTblCopy = finalSumTble.copy()\n",
    "        capsuleFinalTblCopy[\"capsule_duration\"] = (\n",
    "            capsuleFinalTblCopy[\"capsule_duration\"].dt.total_seconds() / 3600\n",
    "        )\n",
    "\n",
    "        capsuleFinalTblCopy = capsuleFinalTblCopy.rename(\n",
    "            columns={\n",
    "                \"SignalName\": \"Signal Name\",\n",
    "                \"capsule_duration\": \"capsule_duration (h)\",\n",
    "                \"countCapsules\": \"Number of Capsules\",\n",
    "            }\n",
    "        )\n",
    "        gridOps = {\n",
    "            # SlickGrid options\n",
    "            \"fullWidthRows\": False,\n",
    "            \"syncColumnCellResize\": True,\n",
    "            \"forceFitColumns\": False,\n",
    "            \"forceSyncScrolling\": False,\n",
    "            #     'defaultColumnWidth': 150,\n",
    "            \"rowHeight\": 25,\n",
    "            \"enableColumnReorder\": True,\n",
    "            \"enableTextSelectionOnCells\": False,\n",
    "            \"editable\": True,\n",
    "            \"autoEdit\": False,\n",
    "            \"explicitInitialization\": True,\n",
    "            # Qgrid options\n",
    "            \"maxVisibleRows\": 5,\n",
    "            \"minVisibleRows\": 5,\n",
    "            \"sortable\": True,\n",
    "            \"filterable\": True,\n",
    "            \"highlightSelectedCell\": False,\n",
    "            \"highlightSelectedRow\": True,\n",
    "        }\n",
    "\n",
    "        qgrid_widget = qgrid.show_grid(\n",
    "            capsuleFinalTblCopy,\n",
    "            show_toolbar=False,\n",
    "            grid_options=gridOps,\n",
    "            column_definitions={\n",
    "                \"index\": {\"maxWidth\": 0, \"minWidth\": 0, \"width\": 0},\n",
    "                \"Name\": {\"maxWidth\": None, \"minWidth\": None, \"width\": 280},\n",
    "            },\n",
    "        )\n",
    "        return qgrid_widget\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".en",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "46ee7536dd6129b1750271aa5d1be5a6c190376cfa1d06083fca28f09803f50e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
